{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-18T18:06:29.482328Z",
     "start_time": "2020-05-18T18:06:29.222749Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/Users/RobertAdragna/Documents/School/Fourth_Year/ESC499-Thesis/codebases/causal_discovery')\n",
    "\n",
    "import copy \n",
    "import os \n",
    "import shutil\n",
    "import itertools\n",
    "from collections import Counter\n",
    "import json\n",
    "import pickle\n",
    "import pprint\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-18T18:06:29.717870Z",
     "start_time": "2020-05-18T18:06:29.484804Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "plt.rcParams['figure.figsize'] = [6, 8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-18T18:06:30.395127Z",
     "start_time": "2020-05-18T18:06:29.720556Z"
    }
   },
   "outputs": [],
   "source": [
    "import models\n",
    "import data_processing as dp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-18T18:06:30.402815Z",
     "start_time": "2020-05-18T18:06:30.397749Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.DS_Store', '.ipynb_checkpoints', '0226_pre-standard', '0409_adult-alldata', '0409_german-alldata', '0410_adult-nodata', '0410_german-nodata', '0413_reddata1000', '0501_reddata10000', '0501_reddata2000', '0501_reddata20000', '0501_reddata5000', '0505_reddata1-20t', '__pycache__', 'analysis.ipynb', 'backwards_compatibility', 'plotting.ipynb', 'processed_results', 'testyalpha.pkl']\n"
     ]
    }
   ],
   "source": [
    "print(os.listdir(os.getcwd()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-18T18:06:30.413281Z",
     "start_time": "2020-05-18T18:06:30.405307Z"
    }
   },
   "outputs": [],
   "source": [
    "res_dir = '0505_reddata1-20t'\n",
    "extra = ''\n",
    "expdir = os.path.join(os.path.join(os.getcwd(), res_dir), 'causal_discovery')\n",
    "savedir = os.path.join(os.path.join(os.getcwd(), res_dir), '{}_{}'.format(res_dir, extra))\n",
    "\n",
    "if os.path.exists(savedir):\n",
    "    shutil.rmtree(savedir)\n",
    "os.mkdir(savedir)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utility Functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-18T18:06:30.420208Z",
     "start_time": "2020-05-18T18:06:30.415809Z"
    }
   },
   "outputs": [],
   "source": [
    "def dataset_name_from_unid(uid):\n",
    "    if 'adult' in uid:\n",
    "        return 'adult'\n",
    "    if 'german' in uid:\n",
    "        return 'germanCredit'\n",
    "    \n",
    "    assert True == False "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-18T18:06:30.430082Z",
     "start_time": "2020-05-18T18:06:30.422870Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_hps_from_rawres(fname):\n",
    "    '''rawres fname -> features'''\n",
    "    unique_id = (fname.split('rawres_')[1]).split('.json')[0]\n",
    "    alpha = unique_id.split('_')[0]\n",
    "    feateng = unique_id.split('_')[1]\n",
    "    dataset = unique_id.split('_')[2]\n",
    "    redsize = unique_id.split('_')[3]\n",
    "    seed = unique_id.split('_')[4]\n",
    "    environment = unique_id.split('_')[5]\n",
    "    \n",
    "    return feateng, dataset, seed, environment, redsize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-18T18:06:30.439916Z",
     "start_time": "2020-05-18T18:06:30.434725Z"
    }
   },
   "outputs": [],
   "source": [
    "def str_2_pcp(pcpstr):\n",
    "    pcpstr = (pcpstr.split('(')[1]).split(')')[0]\n",
    "    pcpstr = pcpstr.replace(' ', '')\n",
    "    ret = set([e.strip(\"'\") for e in pcpstr.split(',')])\n",
    "    ret.discard('')\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-18T18:06:30.486832Z",
     "start_time": "2020-05-18T18:06:30.443733Z"
    }
   },
   "outputs": [],
   "source": [
    "import enum \n",
    "#Part 1\n",
    "START_ALPHA = 1.0\n",
    "FACTOR = 2\n",
    "EPS = 1e-20\n",
    "#Part 2\n",
    "STEP = 1e-2\n",
    "FACTOR2 = 2\n",
    "EPS2 = 1e-10\n",
    "\n",
    "class POS(enum.Enum):\n",
    "   big = 1\n",
    "   small = 2\n",
    "   perf = 3\n",
    "\n",
    "def alpha_tune(pVals, amin, flag=0):\n",
    "    #First find a CP returning alpha \n",
    "    a0 = START_ALPHA\n",
    "    bounds0 = [0, 100.0]\n",
    "    cp_ret = False \n",
    "    while not cp_ret:\n",
    "        pos = 0\n",
    "        accepted = pVals[pVals['Final_tstat'] > a0]\n",
    "        \n",
    "        #Determine position of alpha \n",
    "        if len(accepted.index) == 0:\n",
    "            pos = POS.big\n",
    "        else: \n",
    "            accepted_sets = [str_2_pcp(a) for a in list(accepted.index)]\n",
    "            causal_preds = set.intersection(*accepted_sets)\n",
    "            if len(causal_preds) == 0:\n",
    "                pos = POS.small \n",
    "            else:\n",
    "                pos = POS.perf\n",
    "                cp_ret = True\n",
    "                \n",
    "                if flag:\n",
    "                    print(causal_preds)\n",
    "                    print(a0)\n",
    "                \n",
    "                continue\n",
    "                \n",
    "        #Determine what alpha to check next \n",
    "        if pos == POS.big:\n",
    "            bounds0[1] = a0\n",
    "            if a0/FACTOR <= bounds0[0]:\n",
    "                a0 = a0 - abs((a0 - bounds0[0])/2)\n",
    "            else:\n",
    "                a0 = a0/FACTOR\n",
    "        elif pos == POS.small:\n",
    "            bounds0[0] = a0\n",
    "            if a0 * FACTOR >= bounds0[1]:\n",
    "                a0 = a0 + abs((a0 - bounds0[1])/2)\n",
    "            else:\n",
    "                a0 = a0 * FACTOR\n",
    "        \n",
    "        #Stability check in case no CPs \n",
    "        if abs(bounds0[0] - bounds0[1]) < EPS:\n",
    "            return (-1, -1)\n",
    "    \n",
    "    #Then establish interval bounds \n",
    "    lowerB = [0, a0]\n",
    "    upperB = [a0, 100]\n",
    "    \n",
    "    #Upper Bound\n",
    "    a1 = a0\n",
    "    step = STEP\n",
    "    pos = POS.perf\n",
    "    while abs(upperB[0] - upperB[1]) > EPS2:\n",
    "        a1 = a1 + step\n",
    "        accepted = pVals[pVals['Final_tstat'] > a1]\n",
    "        \n",
    "        #Determine position of alpha \n",
    "        if len(accepted.index) == 0:\n",
    "            pos = POS.big\n",
    "        else:\n",
    "            pos = POS.perf\n",
    "        \n",
    "        #Determine what alpha to check next \n",
    "        if pos == POS.perf:\n",
    "            upperB[0] = a1\n",
    "            if a1 + abs(step * FACTOR2) >= upperB[1]:\n",
    "                step = abs(a1 - upperB[1])/FACTOR2\n",
    "            else:\n",
    "                step = abs(step * FACTOR2) \n",
    "        elif pos == POS.big:\n",
    "            upperB[1] = a1\n",
    "            if (a1 - abs(step * FACTOR2)) <= upperB[0]:\n",
    "                step = -1 * abs(a1 - upperB[0])/FACTOR2\n",
    "            else:\n",
    "                step = -1 * abs(step * FACTOR2) \n",
    "        else:\n",
    "            assert False\n",
    "\n",
    "    #Lower Bound\n",
    "    a2 = a0\n",
    "    if a2 - STEP > 1e-20:\n",
    "        step = STEP\n",
    "    else: \n",
    "        step = a2/FACTOR2 \n",
    "    pos = POS.perf\n",
    "    while abs(lowerB[0] - lowerB[1]) > EPS2:\n",
    "        a2 = a2 - step\n",
    "        accepted = pVals[pVals['Final_tstat'] > a2]\n",
    "        \n",
    "        #Determine position of alpha \n",
    "        accepted_sets = [str_2_pcp(a) for a in list(accepted.index)]\n",
    "        causal_preds = set.intersection(*accepted_sets)\n",
    "        if len(causal_preds) == 0:\n",
    "            pos = POS.small \n",
    "        else:\n",
    "            pos = POS.perf       \n",
    "        \n",
    "        #Determine what alpha to check next \n",
    "        if pos == POS.perf:\n",
    "            lowerB[1] = a2\n",
    "            if a2 - abs(step * FACTOR2) <= lowerB[0]:\n",
    "                step = abs(a2 - lowerB[0])/FACTOR2\n",
    "            else:\n",
    "                step = abs(step * FACTOR2) \n",
    "        elif pos == POS.small:\n",
    "            lowerB[0] = a2\n",
    "            if (a1 + abs(step * FACTOR2)) >= lowerB[1]:\n",
    "                step = -1 * abs(a2 - lowerB[1])/FACTOR2\n",
    "            else:\n",
    "                step = -1 * abs(step * FACTOR2) \n",
    "        else:\n",
    "            assert False\n",
    "    \n",
    "    #Check if interval is too close to 0 to be meaningful \n",
    "    if a2 < amin: \n",
    "        return (-1, -1)\n",
    "        \n",
    "    #Establish 0-padding to interval\n",
    "    interval = abs(a1 - a2)/5\n",
    "    \n",
    "    assert (a2 < a0) and (a0 < a1)\n",
    "    \n",
    "    return (max(0, a2 - interval), a1 + interval)\n",
    "\n",
    "\n",
    "def max_alpha(pVals, arange, eps=1000): \n",
    "    '''Given a computed range of CP returning alphas (maybe with interval) and pvals for exp, return highest CP returning alpha'''\n",
    "    ctr = arange[1]\n",
    "    while ctr > arange[0]:\n",
    "        accepted = pVals[pVals['Final_tstat'] > ctr]\n",
    "        if len(accepted.index) > 0:\n",
    "            return ctr\n",
    "        else:\n",
    "            ctr = ctr - (arange[1] - arange[0])/eps\n",
    "    return -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# # File Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-18T18:06:30.497718Z",
     "start_time": "2020-05-18T18:06:30.490155Z"
    }
   },
   "outputs": [],
   "source": [
    "#Collect all files appropiate to each unique identifier \n",
    "rawres_files= []\n",
    "for f in os.listdir(expdir):\n",
    "    if ('rawres_' in f):\n",
    "        rawres_files.append(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-18T18:06:30.506848Z",
     "start_time": "2020-05-18T18:06:30.500876Z"
    }
   },
   "outputs": [],
   "source": [
    "def open_pvals(filename):\n",
    "    try:\n",
    "        pvals = json.load(open(filename, 'rb'))\n",
    "        del pvals[\"()\"]\n",
    "    except:\n",
    "        return None\n",
    "    pvals = pd.DataFrame.from_dict(pvals, orient='index')\n",
    "    return pvals\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-18T16:06:31.384550Z",
     "start_time": "2020-05-18T16:05:10.891055Z"
    }
   },
   "outputs": [],
   "source": [
    "#Generate Alphas \n",
    "NUM_POINTS = 100\n",
    "MIN_ALPHA = 1e-4\n",
    "\n",
    "alphas = {}\n",
    "for fname in rawres_files:\n",
    "    pvals = open_pvals(os.path.join(expdir, fname))\n",
    "    if pvals is None:\n",
    "        continue\n",
    "    f, d, s, e, rd = get_hps_from_rawres(fname) \n",
    "    arange = alpha_tune(pvals, MIN_ALPHA)\n",
    "    alphas[(f, rd, s, d, e)] = [x for x in arange] + [NUM_POINTS] + [max_alpha(pvals, arange)]\n",
    "#     if (f == '1') and (rd == '1000') and (s == '1000') and (d == 'adult') and (e == 'native-country'):\n",
    "#         arange = alpha_tune(pvals, MIN_ALPHA)\n",
    "#         print(max_alpha(pvals, arange))\n",
    "#         assert False\n",
    "    \n",
    "alphas = pd.DataFrame(alphas).T\n",
    "alphas.columns = ['start', 'stop', 'num_points', 'max_alpha']\n",
    "alphas.index.names = ['feateng', 'reddata', 'seed', 'dataset', 'env']\n",
    "alphas.head(1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Generate pVals  Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-06T19:17:09.665179Z",
     "start_time": "2020-05-06T19:17:09.661106Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "x_axis = {}  #x,y values  for plot of alpha vs #CPs \n",
    "y_axis = {}\n",
    "CPid_results = {}  #Stores CPids of each expierment \n",
    "\n",
    "for fname in rawres_files:\n",
    "    #Identify exp \n",
    "    f, d, s, e, rd = get_hps_from_rawres(fname)  \n",
    "    unid = '{}_{}_{}_{}_{}'.format(f,d,s,e,rd)\n",
    "    \n",
    "    #Load pvals\n",
    "    pvals = open_pvals(os.path.join(expdir, fname))\n",
    "    if pvals is None:\n",
    "        continue\n",
    "    \n",
    "    #Create entries in all results data structures \n",
    "    x_axis[(f, s, d, e, rd)] = []\n",
    "    y_axis[(f, s, d, e, rd)] = []\n",
    "    CPid_results[(f, s, d, e, rd)] = Counter()\n",
    "\n",
    "    ###Generate Results\n",
    "    \n",
    "    ##For results dependent on all alphas returning CPs \n",
    "    start, stop, num_points = alphas.loc[f, rd, s, d, e][0], alphas.loc[f, rd, s, d, e][1], alphas.loc[f, rd, s, d, e][2]\n",
    "    for a in np.linspace(start, stop, num_points): \n",
    "        accepted = pvals[pvals['Final_tstat'] > a]\n",
    "        if len(accepted.index) > 100000:\n",
    "            raise ValueError('too many subsets: {}'.format(len(accepted.index)))\n",
    "\n",
    "        accepted_sets = list(accepted.index)\n",
    "        accepted_sets = [str_2_pcp(a) for a in accepted_sets]\n",
    "        if len(accepted_sets) > 0:\n",
    "            pcps = set.intersection(*accepted_sets)\n",
    "        else:\n",
    "            pcps = set([])\n",
    "        \n",
    "        #Store Number of Accepted Sets \n",
    "        x_axis[(f, s, d, e, rd)].append(a)\n",
    "        if len(accepted_sets) == 0:\n",
    "            y_axis[(f, s, d, e, rd)].append(0)\n",
    "        else:\n",
    "            y_axis[(f, s, d, e, rd)].append(len(set.intersection(*accepted_sets)))\n",
    "\n",
    "        #Store Causal predictors  \n",
    "        for pcp in pcps: \n",
    "            CPid_results[(f, s, d, e, rd)].update({pcp:1})\n",
    "\n",
    "    ##For results dependant on only max CP-retuning alpha\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-06T17:10:30.055286Z",
     "start_time": "2020-05-06T17:10:30.048990Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "alphas.loc['12', '10000', '1000', 'adult', 'marital-status'] [3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-06T17:12:26.015469Z",
     "start_time": "2020-05-06T17:12:25.974422Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "###Test Code for getting the coefficients \n",
    "def hack_pcp2str()\n",
    "\n",
    "for fname in rawres_files[0:1]:\n",
    "    #Get Pvals for environment of interest\n",
    "    pvals = open_pvals(os.path.join(expdir, fname))\n",
    "    if pvals is None:\n",
    "        continue\n",
    "    f, d, s, e, rd = get_hps_from_rawres(fname) \n",
    "    #Get alpha of interest and comptue its associated CPs \n",
    "    max_a = alphas.loc[f, rd, s, d, e][3]\n",
    "    accepted = pvals[pvals['Final_tstat'] > max_a]\n",
    "    accepted_sets = list(accepted.index)\n",
    "    accepted_sets = [str_2_pcp(a) for a in accepted_sets]\n",
    "    \n",
    "    #For the given pval file, \n",
    "print(str(accepted_sets[0]))\n",
    "pvals.head()   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Coefficients Results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-18T18:06:33.234466Z",
     "start_time": "2020-05-18T18:06:33.227278Z"
    }
   },
   "outputs": [],
   "source": [
    "testymctestace = 'testyalpha.pkl'\n",
    "alphas = pd.read_pickle(testymctestace)\n",
    "# data['age']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-18T18:06:43.863322Z",
     "start_time": "2020-05-18T18:06:33.978383Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9973, 747)\n",
      "(9974, 747)\n",
      "(9968, 747)\n",
      "(9969, 747)\n",
      "(9969, 747)\n",
      "(9968, 747)\n",
      "(9975, 747)\n",
      "(9971, 747)\n",
      "(9978, 747)\n",
      "(9974, 747)\n"
     ]
    }
   ],
   "source": [
    "NUM_COEFFS = 25\n",
    "dataset_fname = '/Users/RobertAdragna/Documents/School/Fourth_Year/ESC499-Thesis/codebases/causal_discovery/data/adult.csv'\n",
    "coeffs = {}\n",
    "\n",
    "for fname in rawres_files[5:15]:\n",
    "    #Identify exp \n",
    "    f, d, s, e, rd = get_hps_from_rawres(fname)  \n",
    "    unid = 'causalcoeffs_{}_{}_{}_{}_{}'.format(f,d,s,e,rd)\n",
    "    key_id = (f, s, d, e, rd)\n",
    "    \n",
    "    #Record Result\n",
    "    coeffs[key_id] = {}\n",
    "    \n",
    "    #Get Data \n",
    "    data, y_all, d_atts = dp.adult_dataset_processing(dataset_fname, \\\n",
    "                              [int(c) for c in f], reduce_dsize=int(rd), \\\n",
    "                              estrat_red=1, \\\n",
    "                              testing=0)\n",
    "    env_datts = {e:d_atts[e]}\n",
    "    eq_estrat = -1\n",
    "    \n",
    "    #Load pvals\n",
    "    pvals = open_pvals(os.path.join(expdir, fname))\n",
    "    if pvals is None:\n",
    "        continue\n",
    "        \n",
    "    #Get the Causal Predictors \n",
    "    accepted = pvals[pvals['Final_tstat'] > alphas.loc[f, rd, s, d, e]['max_alpha']]\n",
    "    accepted_sets = [str_2_pcp(a) for a in list(accepted.index)]\n",
    "    causal_preds = set.intersection(*accepted_sets)\n",
    "    \n",
    "    icp = models.InvariantCausalPrediction()\n",
    "    causal_preds = icp.get_data_regressors(d_atts, causal_preds, [int(c) for c in f], data)\n",
    "    res = icp.get_coeffs(causal_preds, data, y_all, env_datts, eq_estrat, int(s))\n",
    "#     if res is not None:\n",
    "#         break\n",
    "    \n",
    "    coeffs[key_id]['final'] = res\n",
    "    \n",
    "    \n",
    "    \n",
    "#     #Get Environment Info \n",
    "#     env_atts = [d_atts[e]]\n",
    "#     e_ins_store = {}\n",
    "#     for env in itertools.product(*env_atts):\n",
    "#         dummy_envs = []\n",
    "#         live_envs = []\n",
    "#         for att in env:\n",
    "#             if '_DUMmY' in att:\n",
    "#                 dummy_envs = [d for d in d_atts[att.split('_')[0]] if d != att]\n",
    "#             else:\n",
    "#                 live_envs.append(att)\n",
    "\n",
    "#         #Compute e_in without error\n",
    "#         if not dummy_envs:\n",
    "#             e_in = ((data[live_envs] == 1)).all(1)\n",
    "#         elif not live_envs:\n",
    "#             e_in = ((data[dummy_envs] == 0)).all(1)\n",
    "#         else:\n",
    "#             e_in = ((data[live_envs] == 1).all(1) & (data[dummy_envs] == 0).all(1))\n",
    "#         e_ins_store[str(env)] = e_in\n",
    "    \n",
    "#     #Linear regression on all data\n",
    "#     regressors = get_data_regressors(d_atts, [x.strip('\"').strip(\"''\") for x in causal_preds], \\\n",
    "#                                      [int(c) for c in f], data)\n",
    "#     x_s = data[list(itertools.chain(regressors))]\n",
    "#     if x_s.shape[1] == 0: \n",
    "# #         print('{} has no CPs'.format(unid))\n",
    "#         continue\n",
    "    \n",
    "#     #Store Causal coefficients for each env \n",
    "#     for env, e_in in e_ins_store.items():\n",
    "#         c = (LinearRegression(fit_intercept=False).fit(x_s.loc[e_in].values, y_all.loc[e_in].values)).coef_[0]\n",
    "#         n = list(x_s.columns) \n",
    "#         assert len(c) == len(n)\n",
    "#         coeffs[key_id][env] = sorted(zip(c, n), reverse=True, key=lambda x: abs(x[0]))[:NUM_COEFFS]\n",
    "\n",
    "#     c = (LinearRegression(fit_intercept=False).fit(x_s.values, y_all.values)).coef_[0]    \n",
    "#     n = list(x_s.columns) \n",
    "#     coeffs[key_id]['final'] = sorted(zip(c, n), reverse=True, key=lambda x: abs(x[0]))[:NUM_COEFFS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-18T18:08:40.194030Z",
     "start_time": "2020-05-18T18:08:40.189349Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys([('12', '147', 'adult', 'marital-status', '10000'), ('12', '147', 'adult', 'native-country', '10000'), ('12', '147', 'adult', 'occupation', '10000'), ('12', '147', 'adult', 'relationship', '10000'), ('12', '147', 'adult', 'workclass', '10000'), ('12', '256', 'adult', 'marital-status', '10000'), ('12', '256', 'adult', 'native-country', '10000'), ('12', '256', 'adult', 'occupation', '10000'), ('12', '256', 'adult', 'relationship', '10000'), ('12', '256', 'adult', 'workclass', '10000')])\n"
     ]
    }
   ],
   "source": [
    "print(coeffs.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-18T18:14:14.853127Z",
     "start_time": "2020-05-18T18:14:14.847028Z"
    }
   },
   "outputs": [],
   "source": [
    "import pprint\n",
    "coeffs[('12', '147', 'adult', 'workclass', '10000')]\n",
    "pickle.dump({'hi':'test'}, open('test', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-18T18:14:16.239249Z",
     "start_time": "2020-05-18T18:14:16.235470Z"
    }
   },
   "outputs": [],
   "source": [
    "a = pickle.load(open('test', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-06T22:52:47.898648Z",
     "start_time": "2020-05-06T22:52:47.738220Z"
    }
   },
   "outputs": [],
   "source": [
    "pickle.dump(x_axis, open(os.path.join(savedir, 'x_axis'), 'wb'))\n",
    "pickle.dump(y_axis, open(os.path.join(savedir, 'y_axis'), 'wb'))\n",
    "pickle.dump(CPid_results, open(os.path.join(savedir, 'CPid_results'), 'wb'))\n",
    "pickle.dump(coeffs, open(os.path.join(savedir, 'coeffs'), 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Appendix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## CALIBRATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-05T00:04:01.257200Z",
     "start_time": "2020-05-05T00:03:53.307368Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# #Plot Accepted subsets vs Alpha for specified hyperparams \n",
    "\n",
    "# #fig, axes = plt.subplots(nrows=nrows, ncols=ncols, figsize=(w*5, int(l/w)*5)) #Note - is +2 for reason\n",
    "\n",
    "\n",
    "# for exp in itertools.product(feateng, dataset, seed, environment):\n",
    "#     for fname in rawres_files:\n",
    "#         f, d, s, e, rd = get_hps_from_rawres(fname)\n",
    "#         if (f == exp[0]) and (d == exp[1]) and (s == exp[2]) and (e == exp[3]) and (rd == exp[4]):\n",
    "#             unid = '{}_{}_{}_{}'.format(f,d,s,e, rd)\n",
    "#             try:\n",
    "#                 pvals = json.load(open(os.path.join(expdir, fname), 'rb'))\n",
    "#                 del pvals[\"()\"]\n",
    "#             except:\n",
    "#                 continue\n",
    "#             pvals = pd.DataFrame.from_dict(pvals, orient='index')\n",
    "            \n",
    "#             start, stop, num_points = alphas.loc[f, rd, s, d, e][0], alphas.loc[f, rd, s, d, e][1], alphas.loc[f, rd, s, d, e][2]\n",
    "#             for a in np.linspace(start, stop, num_points): \n",
    "#                 accepted = pvals[pvals['Final_tstat'] > a]\n",
    "#                 if len(accepted.index) == 0:\n",
    "#                     print(a, unid, 0, 'null')\n",
    "#                 elif len(accepted.index) < 1000:\n",
    "#                     accepted_sets = list(accepted.index)\n",
    "#                     accepted_sets = [str_2_pcp(a) for a in accepted_sets]\n",
    "#                     print(a, unid, len(accepted.index), set.intersection(*accepted_sets))\n",
    "#                 else:\n",
    "#                     print(a, unid, len(accepted.index), 'too_many_intersections')\n",
    "            \n",
    "    \n",
    "#     print('#####################################')"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
