{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-29T18:17:09.148836Z",
     "start_time": "2020-04-29T18:17:06.425779Z"
    }
   },
   "outputs": [],
   "source": [
    "import copy \n",
    "import os \n",
    "import itertools\n",
    "from collections import Counter\n",
    "import json\n",
    "import pickle\n",
    "import pprint\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "res_dir = '0413_reddata'\n",
    "expdir = os.path.join(os.path.join(os.getcwd(), res_dir), 'causal_discovery')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Utility Functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-29T18:17:09.183177Z",
     "start_time": "2020-04-29T18:17:09.179068Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def dataset_name_from_unid(uid):\n",
    "    if 'adult' in uid:\n",
    "        return 'adult'\n",
    "    if 'german' in uid:\n",
    "        return 'germanCredit'\n",
    "    \n",
    "    assert True == False "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-29T18:17:09.222120Z",
     "start_time": "2020-04-29T18:17:09.215074Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_hps_from_rawres(fname):\n",
    "    '''rawres fname -> features'''\n",
    "    unique_id = (fname.split('rawres_')[1]).split('.json')[0]\n",
    "    alpha = unique_id.split('_')[0]\n",
    "    feateng = unique_id.split('_')[1]\n",
    "    dataset = unique_id.split('_')[2]\n",
    "    seed = unique_id.split('_')[3]\n",
    "    environment = unique_id.split('_')[4]\n",
    "    return feateng, dataset, seed, environment\n",
    "    \n",
    "     #print('{}_{}_{}_{}'.format(feateng, dataset, seed, environment))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-29T18:17:09.256105Z",
     "start_time": "2020-04-29T18:17:09.250600Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def str_2_pcp(pcpstr):\n",
    "    pcpstr = (pcpstr.split('(')[1]).split(')')[0]\n",
    "    pcpstr = pcpstr.replace(' ', '')\n",
    "    ret = set(pcpstr.split(','))\n",
    "    ret.discard('')\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-29T18:17:09.411445Z",
     "start_time": "2020-04-29T18:17:09.406154Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def eligible_exps(queries, e_list):\n",
    "    '''Gets all experiments from e_list with the queries attributes\n",
    "    param: elist: list of all posible expeirment keys \n",
    "    param: queries: list of terms which must be elements of e_list tuples'''\n",
    "    ret = []\n",
    "    for exp in e_list:\n",
    "        flag = True\n",
    "        for q in queries: \n",
    "            if q not in exp:\n",
    "                flag = False\n",
    "        if flag:\n",
    "            ret.append(exp)\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-29T18:17:10.500874Z",
     "start_time": "2020-04-29T18:17:10.479158Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def norm_ctr(Ctr, n):\n",
    "    '''Returns sorted list (ctr_name, p) of the n most common elements in Ctr, where p is normalized freq'''\n",
    "    sort = [list(x) for x in Ctr.most_common(n)]\n",
    "    norm = len(list(Ctr.elements()))\n",
    "    for t in sort:\n",
    "        t[1] = t[1]/norm\n",
    "    \n",
    "    return sort \n",
    "\n",
    "def add_slist(s1, s2):\n",
    "    'For all common-keyed tuples in s1-2, add prob values. For new ones, add to returned list'\n",
    "    s1_keys = [x[0] for x in s1]\n",
    "    ret = copy.deepcopy(s1)\n",
    "    \n",
    "    for t in s2: \n",
    "        if t[0] not in s1_keys:\n",
    "            ret.append(t)\n",
    "        else:\n",
    "            for cp in ret:\n",
    "                if cp[0] == t[0]:\n",
    "                    cp[1] += t[1]\n",
    "    return ret\n",
    "    \n",
    "def scale_slist(s, nf):\n",
    "    for t in s:\n",
    "        t[1] = t[1]/nf\n",
    "    return s\n",
    "\n",
    "def sqrt_slist(s):\n",
    "    for t in s:\n",
    "        t[1] = np.sqrt(t[1])\n",
    "    return s\n",
    "\n",
    "def sqdiff_slist(s1, means):\n",
    "    '''For every value of m, find the (m, (s-m)^2)'''\n",
    "    s1_keys = [s[0] for s in s1]\n",
    "    ret = []\n",
    "    \n",
    "    for m in means:\n",
    "        if m[0] in s1_keys: \n",
    "            for s in s1:\n",
    "                if m[0] == s[0]:\n",
    "                    ret.append([m[0], ((m[1]-s[1])**2)])\n",
    "        else:\n",
    "            ret.append([m[0], (m[1]**2)])\n",
    "    \n",
    "    return ret\n",
    "\n",
    "def mean_slist(all_exps, results):\n",
    "    '''For all specified experiments, find the list of (CPid, prob) for each and average them'''\n",
    "    cp = []\n",
    "    norm = len(all_exps)\n",
    "    for exp in all_exps: \n",
    "        cp = add_slist(cp, norm_ctr(results[exp], None)) #Add the causal predictors to each \n",
    "    scaled = scale_slist(cp, norm)\n",
    "    return sorted(scaled, key=lambda x:x[1], reverse=True)\n",
    "        \n",
    "\n",
    "def var_slist(all_exps, results):\n",
    "    cp = []\n",
    "    norm = len(all_exps)\n",
    "    means = mean_slist(all_exps, results)\n",
    "    \n",
    "    for exp in all_exps: \n",
    "        cp = add_slist(cp, sqdiff_slist(norm_ctr(results[exp], None), means))\n",
    "\n",
    "    cp = sqrt_slist(scale_slist(cp, norm))\n",
    "    \n",
    "    #Sort in same order as means \n",
    "    ret = []\n",
    "    for m in means:\n",
    "        for e in cp:\n",
    "            if m[0] == e[0]:\n",
    "                ret.append(e)\n",
    "    \n",
    "    return ret\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-29T21:59:19.173636Z",
     "start_time": "2020-04-29T21:59:19.141540Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import enum \n",
    "#Part 1\n",
    "START_ALPHA = 1.0\n",
    "FACTOR = 2\n",
    "EPS = 1e-20\n",
    "#Part 2\n",
    "STEP = 1e-2\n",
    "FACTOR2 = 2\n",
    "EPS2 = 1e-10\n",
    "\n",
    "class POS(enum.Enum):\n",
    "   big = 1\n",
    "   small = 2\n",
    "   perf = 3\n",
    "\n",
    "def alpha_tune(pVals):\n",
    "    #First find a CP returning alpha \n",
    "    a0 = START_ALPHA\n",
    "    bounds0 = [0, 100.0]\n",
    "    cp_ret = False \n",
    "    while not cp_ret:\n",
    "        pos = 0\n",
    "        accepted = pVals[pVals['Final_tstat'] > a0]\n",
    "        \n",
    "        #Determine position of alpha \n",
    "        if len(accepted.index) == 0:\n",
    "            pos = POS.big\n",
    "        else: \n",
    "            accepted_sets = [str_2_pcp(a) for a in list(accepted.index)]\n",
    "            causal_preds = set.intersection(*accepted_sets)\n",
    "            if len(causal_preds) == 0:\n",
    "                pos = POS.small \n",
    "            else:\n",
    "                pos = POS.perf\n",
    "                cp_ret = True\n",
    "                continue\n",
    "        \n",
    "#         print(a0, bounds0, pos)\n",
    "        #Determine what alpha to check next \n",
    "        if pos == POS.big:\n",
    "            bounds0[1] = a0\n",
    "            if a0/FACTOR <= bounds0[0]:\n",
    "                a0 = a0 - abs((a0 - bounds0[0])/2)\n",
    "            else:\n",
    "                a0 = a0/FACTOR\n",
    "        elif pos == POS.small:\n",
    "            bounds0[0] = a0\n",
    "            if a0 * FACTOR >= bounds0[1]:\n",
    "                a0 = a0 + abs((a0 - bounds0[1])/2)\n",
    "            else:\n",
    "                a0 = a0 * FACTOR\n",
    "        \n",
    "        #Stability check in case no CPs \n",
    "        if abs(bounds0[0] - bounds0[1]) < EPS:\n",
    "            return None\n",
    "    \n",
    "    #Then establish interval bounds \n",
    "    lowerB = [0, a0]\n",
    "    upperB = [a0, 100]\n",
    "    \n",
    "    #Upper Bound\n",
    "    a1 = a0\n",
    "    step = STEP\n",
    "    pos = POS.perf\n",
    "    while abs(upperB[0] - upperB[1]) > EPS2:\n",
    "        a1 = a1 + step\n",
    "        accepted = pVals[pVals['Final_tstat'] > a1]\n",
    "        \n",
    "        #Determine position of alpha \n",
    "        if len(accepted.index) == 0:\n",
    "            pos = POS.big\n",
    "        else:\n",
    "            pos = POS.perf\n",
    "        \n",
    "        #Determine what alpha to check next \n",
    "        if pos == POS.perf:\n",
    "            upperB[0] = a1\n",
    "            if a1 + abs(step * FACTOR2) >= upperB[1]:\n",
    "                step = abs(a1 - upperB[1])/FACTOR2\n",
    "            else:\n",
    "                step = abs(step * FACTOR2) \n",
    "        elif pos == POS.big:\n",
    "            upperB[1] = a1\n",
    "            if (a1 - abs(step * FACTOR2)) <= upperB[0]:\n",
    "                step = -1 * abs(a1 - upperB[0])/FACTOR2\n",
    "            else:\n",
    "                step = -1 * abs(step * FACTOR2) \n",
    "        else:\n",
    "            assert False\n",
    "\n",
    "    #Lower Bound\n",
    "    a2 = a0\n",
    "    if a2 - STEP > 1e-20:\n",
    "        step = STEP\n",
    "    else: \n",
    "        step = a2/FACTOR2 \n",
    "    pos = POS.perf\n",
    "    while abs(lowerB[0] - lowerB[1]) > EPS2:\n",
    "        print(a2, lowerB)\n",
    "\n",
    "        a2 = a2 - step\n",
    "        accepted = pVals[pVals['Final_tstat'] > a2]\n",
    "        \n",
    "        #Determine position of alpha \n",
    "        accepted_sets = [str_2_pcp(a) for a in list(accepted.index)]\n",
    "        causal_preds = set.intersection(*accepted_sets)\n",
    "        if len(causal_preds) == 0:\n",
    "            pos = POS.small \n",
    "        else:\n",
    "            pos = POS.perf       \n",
    "        \n",
    "        #Determine what alpha to check next \n",
    "        if pos == POS.perf:\n",
    "            lowerB[1] = a2\n",
    "            if a2 - abs(step * FACTOR2) <= lowerB[0]:\n",
    "                step = abs(a2 - lowerB[0])/FACTOR2\n",
    "            else:\n",
    "                step = abs(step * FACTOR2) \n",
    "        elif pos == POS.small:\n",
    "            lowerB[0] = a2\n",
    "            if (a1 + abs(step * FACTOR2)) >= lowerB[1]:\n",
    "                step = -1 * abs(a2 - lowerB[1])/FACTOR2\n",
    "            else:\n",
    "                step = -1 * abs(step * FACTOR2) \n",
    "        else:\n",
    "            assert False\n",
    "            \n",
    "    return (a2, a1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# # File Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-29T18:17:11.147943Z",
     "start_time": "2020-04-29T18:17:11.142470Z"
    }
   },
   "outputs": [],
   "source": [
    "#Collect all files appropiate to each unique identifier \n",
    "rawres_files= []\n",
    "for f in os.listdir(expdir):\n",
    "    if ('rawres_' in f):\n",
    "        rawres_files.append(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-29T18:17:23.653023Z",
     "start_time": "2020-04-29T18:17:23.624666Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">1000</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">adult</th>\n",
       "      <th>marital-status</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>native-country</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>occupation</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>relationship</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>workclass</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">147</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">adult</th>\n",
       "      <th>marital-status</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>native-country</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>occupation</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>relationship</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>workclass</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">256</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">adult</th>\n",
       "      <th>marital-status</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>native-country</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>occupation</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>relationship</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>workclass</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">304</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">adult</th>\n",
       "      <th>marital-status</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>native-country</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>occupation</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>relationship</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>workclass</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">52</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">adult</th>\n",
       "      <th>marital-status</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>native-country</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>occupation</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>relationship</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>workclass</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">587</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">adult</th>\n",
       "      <th>marital-status</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>native-country</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>occupation</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>relationship</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>workclass</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">737</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">adult</th>\n",
       "      <th>marital-status</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>native-country</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>occupation</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>relationship</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>workclass</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">784</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">adult</th>\n",
       "      <th>marital-status</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>native-country</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>occupation</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>relationship</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>workclass</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">8079</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">adult</th>\n",
       "      <th>marital-status</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>native-country</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>occupation</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>relationship</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>workclass</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">990</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">adult</th>\n",
       "      <th>marital-status</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>native-country</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>occupation</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>relationship</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>workclass</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           0\n",
       "1000 adult marital-status  0\n",
       "           native-country  0\n",
       "           occupation      0\n",
       "           relationship    0\n",
       "           workclass       0\n",
       "147  adult marital-status  0\n",
       "           native-country  0\n",
       "           occupation      0\n",
       "           relationship    0\n",
       "           workclass       0\n",
       "256  adult marital-status  0\n",
       "           native-country  0\n",
       "           occupation      0\n",
       "           relationship    0\n",
       "           workclass       0\n",
       "304  adult marital-status  0\n",
       "           native-country  0\n",
       "           occupation      0\n",
       "           relationship    0\n",
       "           workclass       0\n",
       "52   adult marital-status  0\n",
       "           native-country  0\n",
       "           occupation      0\n",
       "           relationship    0\n",
       "           workclass       0\n",
       "587  adult marital-status  0\n",
       "           native-country  0\n",
       "           occupation      0\n",
       "           relationship    0\n",
       "           workclass       0\n",
       "737  adult marital-status  0\n",
       "           native-country  0\n",
       "           occupation      0\n",
       "           relationship    0\n",
       "           workclass       0\n",
       "784  adult marital-status  0\n",
       "           native-country  0\n",
       "           occupation      0\n",
       "           relationship    0\n",
       "           workclass       0\n",
       "8079 adult marital-status  0\n",
       "           native-country  0\n",
       "           occupation      0\n",
       "           relationship    0\n",
       "           workclass       0\n",
       "990  adult marital-status  0\n",
       "           native-country  0\n",
       "           occupation      0\n",
       "           relationship    0\n",
       "           workclass       0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_combos = []\n",
    "for fname in rawres_files:\n",
    "    f, d, s, e = get_hps_from_rawres(fname) \n",
    "    total_combos.append((s, d, e))\n",
    "total_combos = pd.DataFrame({x:[0] for x in total_combos}).T\n",
    "total_combos.head(1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-29T19:39:38.303900Z",
     "start_time": "2020-04-29T19:39:38.285525Z"
    }
   },
   "outputs": [],
   "source": [
    "feateng = ['12']\n",
    "dataset = ['adult']  #['adult', germanCredit']\n",
    "seed = ['8079']  #, '8079', '52', '147', '256', '784', '990', '587', '304','737']\n",
    "environment = ['workclass'] \n",
    "\n",
    "available_exps = itertools.product(feateng, dataset, seed, environment)\n",
    "\n",
    "alphas = {'8079':{'adult':{'workclass':(0.1, 0.6, 100),\\\n",
    "                           'occupation':(1e-6, 1e-4, 100),\\\n",
    "                           'native-country':(0.5, 1.5, 100),\\\n",
    "                           'marital-status':(1e-60, 1e-20, 100)},\\\n",
    "                  'german':{'Purpose':(3.5, 5.5, 100), \\\n",
    "                            'Housing':(1.6, 3.0, 100), \\\n",
    "                            'Telephone':(3.0, 4.0, 100), \\\n",
    "                            'Property':(4, 5.5, 100)} \\\n",
    "                 },\n",
    "          '1000':{'adult':{'workclass':(0.1, 0.6, 100),\\\n",
    "                           'occupation':(1e-6, 1e-4, 100),\\\n",
    "                           'native-country':(1e-2, 0.15, 100),\\\n",
    "                           'marital-status':(1e-60, 1e-20, 100)},\\\n",
    "                  'german':{'Purpose':(3.5, 5.5, 100), \\\n",
    "                            'Housing':(1.6, 3.0, 100), \\\n",
    "                            'Telephone':(3.0, 4.0, 100), \\\n",
    "                            'Property':(4, 5.5, 100)} \\\n",
    "                 }\n",
    "}\n",
    "\n",
    "alphas = pd.DataFrame({(s, d, e):alphas[s][d][e] for s in alphas.keys() for d in alphas[s].keys() for e in alphas[s][d].keys()}).T\n",
    "alphas.columns = ['start', 'stop', 'num_points']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CALIBRATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-29T21:58:51.226879Z",
     "start_time": "2020-04-29T21:58:51.169438Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.125 [0, 0.125]\n",
      "0.115 [0, 0.115]\n",
      "0.095 [0.095, 0.115]\n",
      "0.10500000000000001 [0.10500000000000001, 0.115]\n",
      "0.11000000000000001 [0.10500000000000001, 0.11000000000000001]\n",
      "0.10750000000000001 [0.10750000000000001, 0.11000000000000001]\n",
      "0.10875000000000001 [0.10875000000000001, 0.11000000000000001]\n",
      "0.10937500000000001 [0.10875000000000001, 0.10937500000000001]\n",
      "0.1090625 [0.10875000000000001, 0.1090625]\n",
      "0.10890625000000001 [0.10890625000000001, 0.1090625]\n",
      "0.10898437500000001 [0.10890625000000001, 0.10898437500000001]\n",
      "0.1089453125 [0.1089453125, 0.10898437500000001]\n",
      "0.10896484375000001 [0.10896484375000001, 0.10898437500000001]\n",
      "0.108974609375 [0.10896484375000001, 0.108974609375]\n",
      "0.10896972656250001 [0.10896484375000001, 0.10896972656250001]\n",
      "0.10896728515625001 [0.10896484375000001, 0.10896728515625001]\n",
      "0.10896606445312501 [0.10896606445312501, 0.10896728515625001]\n",
      "0.10896667480468751 [0.10896667480468751, 0.10896728515625001]\n",
      "0.10896697998046875 [0.10896667480468751, 0.10896697998046875]\n",
      "0.10896682739257812 [0.10896667480468751, 0.10896682739257812]\n",
      "0.10896675109863282 [0.10896667480468751, 0.10896675109863282]\n",
      "0.10896671295166016 [0.10896667480468751, 0.10896671295166016]\n",
      "0.10896669387817384 [0.10896667480468751, 0.10896669387817384]\n",
      "0.10896668434143067 [0.10896668434143067, 0.10896669387817384]\n",
      "0.10896668910980226 [0.10896668910980226, 0.10896669387817384]\n",
      "0.10896669149398805 [0.10896669149398805, 0.10896669387817384]\n",
      "0.10896669268608095 [0.10896669149398805, 0.10896669268608095]\n",
      "0.1089666920900345 [0.1089666920900345, 0.10896669268608095]\n",
      "0.10896669238805773 [0.1089666920900345, 0.10896669238805773]\n",
      "0.10896669223904612 [0.1089666920900345, 0.10896669223904612]\n",
      "(0.20077849112451074, 0.1089666921645403)\n"
     ]
    }
   ],
   "source": [
    "for exp in itertools.product(feateng, dataset, seed, environment):\n",
    "    for fname in rawres_files:\n",
    "        f, d, s, e = get_hps_from_rawres(fname)\n",
    "        if (f == exp[0]) and (d == exp[1]) and (s == exp[2]) and (e == exp[3]):\n",
    "            unid = '{}_{}_{}_{}'.format(f,d,s,e)\n",
    "            try:\n",
    "                pvals = json.load(open(os.path.join(expdir, fname), 'rb'))\n",
    "                del pvals[\"()\"]\n",
    "            except:\n",
    "                continue\n",
    "            pvals = pd.DataFrame.from_dict(pvals, orient='index')\n",
    "            print(alpha_tune(pvals))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-29T21:59:44.232308Z",
     "start_time": "2020-04-29T21:59:44.228379Z"
    }
   },
   "outputs": [],
   "source": [
    "# #Plot Accepted subsets vs Alpha for specified hyperparams \n",
    "\n",
    "# #fig, axes = plt.subplots(nrows=nrows, ncols=ncols, figsize=(w*5, int(l/w)*5)) #Note - is +2 for reason\n",
    "\n",
    "\n",
    "for exp in itertools.product(feateng, dataset, seed, environment):\n",
    "    for fname in rawres_files:\n",
    "        f, d, s, e = get_hps_from_rawres(fname)\n",
    "        if (f == exp[0]) and (d == exp[1]) and (s == exp[2]) and (e == exp[3]):\n",
    "            unid = '{}_{}_{}_{}'.format(f,d,s,e)\n",
    "            try:\n",
    "                pvals = json.load(open(os.path.join(expdir, fname), 'rb'))\n",
    "                del pvals[\"()\"]\n",
    "            except:\n",
    "                continue\n",
    "            pvals = pd.DataFrame.from_dict(pvals, orient='index')\n",
    "            \n",
    "            start, stop, num_points = alphas.loc[s, d, e][0], alphas.loc[s, d, e][1], alphas.loc[s, d, e][2]\n",
    "            for a in np.linspace(start, stop, num_points): \n",
    "                accepted = pvals[pvals['Final_tstat'] > a]\n",
    "                if len(accepted.index) == 0:\n",
    "                    print(a, unid, 0, 'null')\n",
    "                elif len(accepted.index) < 1000:\n",
    "                    accepted_sets = list(accepted.index)\n",
    "                    accepted_sets = [str_2_pcp(a) for a in accepted_sets]\n",
    "                    print(a, unid, len(accepted.index), set.intersection(*accepted_sets))\n",
    "                else:\n",
    "                    print(a, unid, len(accepted.index), 'too_many_intersections')\n",
    "            \n",
    "    \n",
    "    print('#####################################')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Number PCPS Accepted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-29T00:32:32.685709Z",
     "start_time": "2020-04-29T00:32:32.491636Z"
    }
   },
   "outputs": [],
   "source": [
    "x_axis = {}  #x,y values  for plot of alpha vs #CPs \n",
    "y_axis = {}\n",
    "CPid_results = {}  #Stores CPids of each expierment \n",
    "# assert len(list(itertools.product(feateng, dataset, seed, environment))) == 1\n",
    "\n",
    "for exp in available_exps:\n",
    "    for fname in rawres_files:\n",
    "        f, d, s, e = get_hps_from_rawres(fname)  \n",
    "        if (f == exp[0]) and (d == exp[1]) and (s == exp[2]) and (e == exp[3]):\n",
    "            unid = '{}_{}_{}_{}'.format(f,d,s,e)\n",
    "            try:\n",
    "                pvals = json.load(open(os.path.join(expdir, fname), 'rb'))\n",
    "                del pvals[\"()\"]\n",
    "            except:\n",
    "                continue\n",
    "            pvals = pd.DataFrame.from_dict(pvals, orient='index')\n",
    "            \n",
    "            #For Storing all the results \n",
    "            x_axis[(s, d, e)] = []\n",
    "            y_axis[(s, d, e)] = []\n",
    "            CPid_results[(s, d, e)] = Counter()\n",
    "            norm = 0\n",
    "            \n",
    "            start, stop, num_points = alphas.loc[s, d, e][0], alphas.loc[s, d, e][1], alphas.loc[s, d, e][2]\n",
    "            for a in np.linspace(start, stop, num_points): \n",
    "                accepted = pvals[pvals['Final_tstat'] > a]\n",
    "                if len(accepted.index) > 100000:\n",
    "                    raise ValueError('too many subsets: {}'.format(len(accepted.index)))\n",
    "                \n",
    "                accepted_sets = list(accepted.index)\n",
    "                accepted_sets = [str_2_pcp(a) for a in accepted_sets]\n",
    "                if len(accepted_sets) > 0:\n",
    "                    pcps = set.intersection(*accepted_sets)\n",
    "                else:\n",
    "                    pcps = set([])\n",
    "                \n",
    "                #Number of Accepted Sets \n",
    "                x_axis[(s, d, e)].append(a)\n",
    "                if len(accepted_sets) == 0:\n",
    "                    y_axis[(s, d, e)].append(0)\n",
    "                else:\n",
    "                    y_axis[(s, d, e)].append(len(set.intersection(*accepted_sets)))\n",
    "                    \n",
    "                #Causal predictor  \n",
    "                for pcp in pcps: \n",
    "                    CPid_results[(s, d, e)].update({pcp:1})\n",
    "                    \n",
    "                \n",
    "#                 if len(pcps) > 0:\n",
    "#                     norm += 1\n",
    "#                     for pcp in pcps: \n",
    "#                         if pcp not in CPid_results[(s, d, e)]:\n",
    "#                             CPid_results[(s, d, e)][pcp] = 1 \n",
    "#                         else:\n",
    "#                             CPid_results[(s, d, e)][pcp] += 1\n",
    "                        \n",
    "#             #Causal Predictor More  \n",
    "#             for cat in CPid_results[(s, d, e)]:\n",
    "#                 CPid_results[(s, d, e)][cat] = CPid_results[(s, d, e)][cat]/norm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-28T23:51:53.518730Z",
     "start_time": "2020-04-28T23:51:53.513509Z"
    }
   },
   "outputs": [],
   "source": [
    "norm_ctr(CPid_results[('8079', 'adult', 'workclass')], 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-28T20:21:11.231481Z",
     "start_time": "2020-04-28T20:21:09.020097Z"
    }
   },
   "outputs": [],
   "source": [
    "matplotlib.rcParams.update({'font.size': 26})\n",
    "fig, axes = plt.subplots(nrows=2, ncols=4, figsize=(40, 20))\n",
    "\n",
    "for i, exp in enumerate(x_axis.keys()):  #Assume x_axis, y_axis keys are the same \n",
    "    axes[int(i/4), i%4].plot(x_axis[exp], y_axis[exp])\n",
    "    axes[int(i/4), i%4].set_title(exp)\n",
    "    axes[int(i/4), i%4].set_ylabel('Number Accepted')\n",
    "    axes[int(i/4), i%4].set_xlabel('alpha')\n",
    "plt.ticklabel_format(axis=\"x\", style=\"sci\", scilimits=(0,0))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ALPHA SENSITIVITY PLOTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "##Regular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-28T20:21:17.564361Z",
     "start_time": "2020-04-28T20:21:15.711601Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "colours = ['b', 'g', 'r', 'c', 'k']\n",
    "matplotlib.rcParams.update({'font.size': 16})\n",
    "fig, axes = plt.subplots(nrows=2, ncols=4, figsize=(40, 20))\n",
    "\n",
    "for i, exp in enumerate(CPid_results.keys()):\n",
    "    sort_pcp_sens = norm_ctr(CPid_results[exp], 5)    \n",
    "    \n",
    "    labels = []\n",
    "    bars = []\n",
    "    for d in range(min(5,len(sort_pcp_sens))):\n",
    "        labels.append(sort_pcp_sens[d][0])\n",
    "        bars.append(sort_pcp_sens[d][1])\n",
    "\n",
    "\n",
    "    X = 0 \n",
    "    width = 0.05  # the width of the bars\n",
    "    \n",
    "    axes[int(i/4), i%4].set_title(exp, pad=30)\n",
    "    if (i%4) == 0:\n",
    "        axes[int(i/4), i%4].set_ylabel('Proportion Included', fontsize=32)\n",
    "        axes[int(i/4), i%4].yaxis.labelpad = 40\n",
    "    axes[int(i/4), i%4].set_ylim(0,1)\n",
    "    axes[int(i/4), i%4].tick_params(\n",
    "        axis='x',          # changes apply to the x-axis\n",
    "        which='both',      # both major and minor ticks are affected\n",
    "        bottom=False,      # ticks along the bottom edge are off\n",
    "        top=False,         # ticks along the top edge are off\n",
    "        labelbottom=False) # labels along the \n",
    "    \n",
    "    for d in range(len(labels)):\n",
    "        axes[int(i/4), i%4].bar(X + (d*width), bars[d], color = colours[d], width = width, label=labels[d])\n",
    "    axes[int(i/4), i%4].legend(loc='lower left', prop={'size':30}) \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-28T21:26:02.069631Z",
     "start_time": "2020-04-28T21:26:02.065558Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(CPid_results.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Aggregate Random Seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-29T00:03:43.122630Z",
     "start_time": "2020-04-29T00:03:41.071204Z"
    }
   },
   "outputs": [],
   "source": [
    "colours = ['b', 'g', 'r', 'c', 'k']\n",
    "matplotlib.rcParams.update({'font.size': 16})\n",
    "fig, axes = plt.subplots(nrows=2, ncols=4, figsize=(40, 20))\n",
    "\n",
    "aggregate = {}\n",
    "for i, big_exp in enumerate(list(itertools.product(dataset, environment))):\n",
    "    aggregate[big_exp] = {}\n",
    "    avg_sort_pcp_sens = mean_slist(eligible_exps(big_exp, CPid_results.keys()), CPid_results)\n",
    "    errors = var_slist(eligible_exps(big_exp, CPid_results.keys()), CPid_results)\n",
    "    \n",
    "    labels = []\n",
    "    bars = []\n",
    "    errors_plt = []\n",
    "    for d in range(min(5,len(avg_sort_pcp_sens))):\n",
    "        labels.append(avg_sort_pcp_sens[d][0])\n",
    "        bars.append(avg_sort_pcp_sens[d][1])\n",
    "        errors_plt.append(errors[d][1])\n",
    "\n",
    "    X = 0 \n",
    "    width = 0.05  # the width of the bars\n",
    "\n",
    "    axes[int(i/4), i%4].set_title(big_exp, pad=30)\n",
    "    if (i%4) == 0:\n",
    "        axes[int(i/4), i%4].set_ylabel('Proportion Included', fontsize=32)\n",
    "        axes[int(i/4), i%4].yaxis.labelpad = 40\n",
    "    axes[int(i/4), i%4].set_ylim(0,1)\n",
    "    axes[int(i/4), i%4].tick_params(\n",
    "        axis='x',          # changes apply to the x-axis\n",
    "        which='both',      # both major and minor ticks are affected\n",
    "        bottom=False,      # ticks along the bottom edge are off\n",
    "        top=False,         # ticks along the top edge are off\n",
    "        labelbottom=False) # labels along the \n",
    "\n",
    "    for d in range(len(labels)):\n",
    "        axes[int(i/4), i%4].bar(X + (d*width), bars[d], color = colours[d], \\\n",
    "                                width = width, label=labels[d], yerr=errors_plt[d])\n",
    "    axes[int(i/4), i%4].legend(loc='lower left', prop={'size':30}) \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "res = np.zeros((4,4))\n",
    "for i, env_1 in enumerate(results.keys()):\n",
    "    for j, env_2 in enumerate(results.keys()):\n",
    "        e1 = set(a[0] for a in sorted(results[env_1].items(), key=lambda kv: kv[1], reverse=True)[:5])\n",
    "        e2 = set(a[0] for a in sorted(results[env_2].items(), key=lambda kv: kv[1], reverse=True)[:5])\n",
    "        res[i,j] = len(set.intersection(e1, e2))\n",
    "        \n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#PARAMS\n",
    "alphas = {'8079':{'workclass':np.linspace(0.1, 0.6, 100),\\\n",
    "                 'occupation':np.linspace(1e-6, 1e-4, 100),\\\n",
    "                 'native-country':np.linspace(0.5, 1.5, 100),\\\n",
    "                 'marital-status':np.linspace(1e-60, 1e-20, 100), \\\n",
    "                 'Purpose':np.linspace(3.5, 5.5, 100), \\\n",
    "                 'Housing':np.linspace(1.6, 3.0, 100), \\\n",
    "                 'Telephone':np.linspace(3.0, 4.0, 100), \\\n",
    "                 'Property':np.linspace(4, 5.5, 100)},\n",
    "         '1000':  {'workclass':np.linspace(0.1, 0.6, 100),\\\n",
    "                 'occupation':np.linspace(1e-6, 1e-4, 100),\\\n",
    "                 'native-country':np.linspace(1e-2, 0.15, 100),\\\n",
    "                 'marital-status':np.linspace(1e-60, 1e-20, 100), \\\n",
    "                 'Purpose':np.linspace(3.5, 5.5, 100), \\\n",
    "                 'Housing':np.linspace(1.6, 3.0, 100), \\\n",
    "                 'Telephone':np.linspace(3.0, 4.0, 100), \\\n",
    "                 'Property':np.linspace(4, 5.5, 100)}\n",
    "}\n",
    "\n",
    "\n",
    "feateng = ['12']\n",
    "dataset = ['adult']  #['adult', germanCredit']\n",
    "seed = ['1000', '8079'] #seeds=(1000 8079 52 147)\n",
    "environment = ['workclass', 'occupation', 'native-country', 'marital-status']\n",
    "log_alpha = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Plot PCP distribution per Enviriornment variable over time \n",
    "assert ((len(dataset) == 1) and ((len(seed) == 1)) ^ (len(feateng) == 1))\n",
    "# fig, axes = plt.subplots(nrows=1, ncols=4)\n",
    "\n",
    "i = 2\n",
    "\n",
    "results = {}\n",
    "for exp in itertools.product(feateng, dataset, seed, environment):\n",
    "    if exp[i] not in results.keys():\n",
    "        results[exp[i]] = {}\n",
    "    if (exp[i] in results.keys()) and (exp[3] not in results[exp[i]].keys()):\n",
    "        results[exp[i]][exp[3]] = {}\n",
    "    print(results.keys(), exp[3])\n",
    "    norm = 0\n",
    "    for fname in rawres_files:\n",
    "        f, d, s, e = get_hps_from_rawres(fname)\n",
    "        if (f == exp[0]) and (d == exp[1]) and (s == exp[2]) and (e == exp[3]):\n",
    "            unid = '{}_{}_{}_{}'.format(f,d,s,e)\n",
    "            try:\n",
    "                pvals = json.load(open(os.path.join(expdir, fname), 'rb'))\n",
    "                del pvals[\"()\"]\n",
    "            except:\n",
    "                continue\n",
    "            pvals = pd.DataFrame.from_dict(pvals, orient='index')\n",
    "            for a in alphas[s][e]: \n",
    "                accepted = pvals[pvals['Final_tstat'] > a]\n",
    "                if len(accepted.index) > 100000:\n",
    "                    raise ValueError('too many subsets: {}'.format(len(accepted.index)))\n",
    "                    \n",
    "                accepted_sets = list(accepted.index)\n",
    "                accepted_sets = [str_2_pcp(a) for a in accepted_sets]\n",
    "                \n",
    "                if len(accepted_sets) == 0:\n",
    "                    continue\n",
    "                pcps = set.intersection(*accepted_sets)   \n",
    "                if len(pcps) == 0:\n",
    "                    continue\n",
    "                else:\n",
    "                    norm += 1\n",
    "                    for pcp in pcps: \n",
    "                        if pcp not in results[exp[i]][exp[3]]:\n",
    "                            results[exp[i]][exp[3]][pcp] = 1 \n",
    "                        else:\n",
    "                            results[exp[i]][exp[3]][pcp] += 1\n",
    "                      \n",
    "                        \n",
    "            \n",
    "            for cat in results[exp[i]][exp[3]]:\n",
    "                results[exp[i]][exp[3]][cat] = results[exp[i]][exp[3]][cat]/norm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(results.keys())\n",
    "print(results['8079']['occupation'])  #.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "colours = ['b', 'g', 'r', 'c', 'k']\n",
    "matplotlib.rcParams.update({'font.size': 26})\n",
    "fig, axes = plt.subplots(nrows=2, ncols=4, figsize=(40, 20))\n",
    "\n",
    "for i, fteng in enumerate(results):\n",
    "    for j, env in enumerate(results[fteng]):\n",
    "        labels = []\n",
    "        bars = []\n",
    "        to_plot = results[fteng][env]\n",
    "        for res in to_plot:\n",
    "            labels.append(res)\n",
    "            bars.append(to_plot[res])\n",
    "        X = 0 \n",
    "        width = 0.05\n",
    "\n",
    "        axes[i,j].set_title('Adult - {} - Seed={}'.format(env.capitalize(), fteng), pad=30)\n",
    "        if j == 0:\n",
    "            axes[i,j].set_ylabel('Proportion Included', fontsize=32)\n",
    "            axes[i,j].yaxis.labelpad = 40\n",
    "        axes[i,j].set_ylim(0,1)\n",
    "        axes[i,j].tick_params(\n",
    "            axis='x',          # changes apply to the x-axis\n",
    "            which='both',      # both major and minor ticks are affected\n",
    "            bottom=False,      # ticks along the bottom edge are off\n",
    "            top=False,         # ticks along the top edge are off\n",
    "            labelbottom=False) # labels along the \n",
    "\n",
    "        if len(labels) > 0:\n",
    "            for d in range(0, min(len(labels), 5)):\n",
    "                axes[i,j].bar(X + (d*width), bars[d], color = colours[d], width = width, label=labels[d])\n",
    "            axes[i,j].legend(loc='lower left', prop={'size':30})\n",
    "             \n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Plot Accepted subsets vs Alpha for specified hyperparams \n",
    "\n",
    "#fig, axes = plt.subplots(nrows=nrows, ncols=ncols, figsize=(w*5, int(l/w)*5)) #Note - is +2 for reason\n",
    "\n",
    "\n",
    "for exp in itertools.product(feateng, dataset, seed, environment):\n",
    "    for fname in rawres_files:\n",
    "        f, d, s, e = get_hps_from_rawres(fname)\n",
    "        if (f == exp[0]) and (d == exp[1]) and (s == exp[2]) and (e == exp[3]):\n",
    "            unid = '{}_{}_{}_{}'.format(f,d,s,e)\n",
    "            try:\n",
    "                pvals = json.load(open(os.path.join(expdir, fname), 'rb'))\n",
    "                del pvals[\"()\"]\n",
    "            except:\n",
    "                continue\n",
    "            pvals = pd.DataFrame.from_dict(pvals, orient='index')\n",
    "            for a in alphas[e]: \n",
    "                accepted = pvals[pvals['Final_tstat'] > a]\n",
    "                if len(accepted.index) == 0:\n",
    "                    print(a, unid, 0, 'null')\n",
    "                elif len(accepted.index) < 1000:\n",
    "                    accepted_sets = list(accepted.index)\n",
    "                    accepted_sets = [str_2_pcp(a) for a in accepted_sets]\n",
    "                    print(a, unid, len(accepted.index), set.intersection(*accepted_sets))\n",
    "                else:\n",
    "                    print(a, unid, len(accepted.index), 'too_many_intersections')\n",
    "            \n",
    "    \n",
    "    print('#####################################')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
