{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-15T02:19:13.339410Z",
     "start_time": "2020-06-15T02:19:13.333146Z"
    }
   },
   "outputs": [],
   "source": [
    "import copy \n",
    "import os \n",
    "from os.path import join\n",
    "import shutil\n",
    "import itertools\n",
    "from collections import Counter\n",
    "import json\n",
    "import pickle\n",
    "import pprint\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pprint\n",
    "import torch \n",
    "import torch.nn.functional as F \n",
    "import math \n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "plt.rcParams['figure.figsize'] = [6, 8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-15T02:19:13.590975Z",
     "start_time": "2020-06-15T02:19:13.587073Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "basedir = '/Users/RobertAdragna/Documents/School/Fourth_Year/ESC499-Thesis/codebases/causal_discovery'\n",
    "sys.path.append(basedir)\n",
    "\n",
    "import data_processing as dp \n",
    "import environment_processing as eproc \n",
    "import models \n",
    "from utils import proc_fteng, make_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-15T02:19:13.813110Z",
     "start_time": "2020-06-15T02:19:13.809038Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.DS_Store', '.ipynb_checkpoints', '00_old_formatting', '0525_smallsample', '0531_allgerman', '0602_validation', '0603_validation', '0610_baseline_adultgerman', '__pycache__', 'final_latex_results', 'latex_results', 'Plot_Generation.ipynb', 'prediction.ipynb']\n"
     ]
    }
   ],
   "source": [
    "print(os.listdir(os.getcwd()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-15T02:19:14.113243Z",
     "start_time": "2020-06-15T02:19:14.104470Z"
    }
   },
   "outputs": [],
   "source": [
    "res_dir = '0610_baseline_adultgerman/testing'\n",
    "invariance_algos = {}   #'icp':{},\n",
    "non_invariance_algos = {'linreg':{}}\n",
    "\n",
    "for als in [invariance_algos, non_invariance_algos]:\n",
    "    for al in als.keys(): \n",
    "        als[al]['expdir'] = join(join(join(os.getcwd(), res_dir), al), 'causal_discovery')\n",
    "        als[al]['processed_dir'] = join(join(join(os.getcwd(), res_dir), al), 'processed_results')\n",
    "        als[al]['params'] = pd.read_pickle(join(join(join(os.getcwd(), res_dir), al), '{}_paramfile.pkl'.format(al)))\n",
    "\n",
    "        if not os.path.exists(als[al]['processed_dir']):\n",
    "            raise Exception('Directory has not yet been processed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-15T02:15:10.397903Z",
     "start_time": "2020-06-15T02:15:10.390962Z"
    }
   },
   "outputs": [],
   "source": [
    "# invariance_algos['linear_irm']['params']['Algo'] = invariance_algos['linear_irm']['params']['Algo'].apply(lambda x: x.replace('_', '-'))\n",
    "# invariance_algos['linear_irm']['params'].tail(10)\n",
    "# non_invariance_algos['linreg']['params'].head()\n",
    "# non_invariance_algos['linreg']['params'].drop('linregressors', axis=1, inplace=True)\n",
    "# non_invariance_algos['linreg']['params'].to_pickle('0610_baseline_adultgerman/testing/linreg/linreg_paramfile.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-15T02:08:49.593387Z",
     "start_time": "2020-06-15T02:08:49.574211Z"
    }
   },
   "outputs": [],
   "source": [
    "def pred_binarize(v):\n",
    "    '''Convert all values to 0 if <0.5, 1 otherwise'''\n",
    "    def thresh(x):\n",
    "        if (x >= 0.5): return 1 \n",
    "        else: return 0\n",
    "    print(v.shape)\n",
    "    return np.apply_along_axis(thresh, 1, v)\n",
    "    \n",
    "        \n",
    "def compute_loss(pred, ground, ltype='MSE'):\n",
    "    '''Compute loss between two prediction vectors'''\n",
    "\n",
    "    \n",
    "    if ltype == 'MSE':\n",
    "        return F.mse_loss(torch.tensor(pred).float(), torch.tensor(ground).float()).numpy()\n",
    "    if ltype == 'ACC':\n",
    "        pred = pred_binarize(pred) \n",
    "        return 1 - F.mse_loss(torch.tensor(pred).float(), torch.tensor(ground).float()).numpy()\n",
    "    \n",
    "def fairness_dp(pred, ground, d, patts, ftype='DP'):\n",
    "    '''Compute demographic aparity wrt data\n",
    "    :param pred: vector, binary entries (np[float])\n",
    "    :param ground: vector, binary entries (np[float])\n",
    "    :param d: dataset (pandas df)\n",
    "    :param patt: datts dict {cat:[all orig columns]}'''\n",
    "    \n",
    "    def avg_diff_scores(p):\n",
    "        ''' Given a dictionary of scores for different sensitive attributes p.keys, \\ \n",
    "            return the average difference between these values '''\n",
    "        na = len(p.keys())\n",
    "        if na <= 1:  #Error checking\n",
    "            return np.nan\n",
    "        \n",
    "        n_combos = math.factorial(na)/ (2 * math.factorial(na - 2))\n",
    "        \n",
    "        tot = 0\n",
    "        for pair in itertools.combinations(list(p.keys()), 2): \n",
    "            tot += abs(p[pair[0]] - p[pair[1]])\n",
    "        \n",
    "        return float(tot/na)\n",
    "\n",
    "    \n",
    "    #Get the protected attribute columns \n",
    "    assert len(patts.keys()) == 1\n",
    "    protected = [patts[cat] for cat in patts.keys()][0]\n",
    "    \n",
    "    probs = {}   \n",
    "    #Compute p(y_hat=1 | a, y)  Va  (demographic parity)\n",
    "\n",
    "    for aval in protected: \n",
    "        if '_DUMmY' in aval:\n",
    "            subpop = (d[[a for a in protected if '_DUMmY' not in a]] == 0).all(1).values.squeeze()\n",
    "        else:\n",
    "            subpop = (d[aval] == 1).values.squeeze()\n",
    "        \n",
    "        #Make sure that there are samples in the group of interest \n",
    "        if (subpop.sum() == 0) or ((subpop & (ground == 1).squeeze()).sum() == 0):\n",
    "            continue\n",
    "        \n",
    "        #Compute fairness\n",
    "        if ftype == 'DP': \n",
    "            probs[aval] = pred[subpop].sum() / len(pred[subpop])\n",
    "        \n",
    "        elif ftype == 'EOP':\n",
    "            probs[aval] = pred[subpop & (ground == 1).squeeze()].sum() / len(pred[subpop & (ground == 1).squeeze()])\n",
    "        \n",
    "        elif ftype == 'CAL':\n",
    "            probs[aval] = ground[subpop & (pred == 1).squeeze()].sum() / len(ground[subpop])\n",
    "\n",
    "    return avg_diff_scores(probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-15T02:08:49.811076Z",
     "start_time": "2020-06-15T02:08:49.805249Z"
    }
   },
   "outputs": [],
   "source": [
    "def df_subset(df, subset):\n",
    "    '''Get a subset of df rows whose columns specified in subset equal their respective values\n",
    "    :param df: Dataframe (pandas)\n",
    "    :param subset: Series of col_name:value pairs (pandas series)\n",
    "    '''\n",
    "    new_df = df.copy(deep=True)\n",
    "    for col, val in pd.Series.iteritems(subset):\n",
    "        new_df = new_df[new_df[col] == val]\n",
    "    return new_df\n",
    "\n",
    "def get_dset_fname(dset, b):\n",
    "    if dset == 'adult':\n",
    "        datafname = join(join(b, 'data'), 'adult.csv')\n",
    "    elif dset == 'german':\n",
    "        datafname = join(join(b, 'data'), 'germanCredit.csv')\n",
    "    else:\n",
    "        raise Exception('Dataset unimplemented')\n",
    "    \n",
    "    return datafname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-15T02:08:50.004634Z",
     "start_time": "2020-06-15T02:08:49.995001Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_all_existing_results(allcols, ags):\n",
    "    ''' param allcols: A list of the features to be included\n",
    "        param ags: A list of paramdfs for each algorithm'''\n",
    "    add = pd.DataFrame()\n",
    "    for param_df in ags: \n",
    "        if add.empty:\n",
    "            add = param_df[allcols]\n",
    "        else:\n",
    "            add = add.append(param_df[allcols], ignore_index=True)\n",
    "    \n",
    "    uniq = np.logical_not(add.duplicated())\n",
    "    return add[uniq]\n",
    "    \n",
    "    \n",
    "def generate_results(fixed, compared): \n",
    "    '''\n",
    "    :param fixed: A list of tuples (pname, pval) that are fixed across exps\n",
    "    :param compared: A dictionary of pname:full range of possible values in experiment ''' \n",
    "    \n",
    "    fixed_results = pd.Series([np.nan]*len(fixed), index=[f[0] for f in fixed]) #  , index=fixed_cols) \n",
    "    for f in fixed:\n",
    "        fixed_results[f[0]] = f[1]\n",
    "    \n",
    "    #Set Up the Results Dataframe \n",
    "    compared_results = pd.DataFrame(itertools.product(*[compared[cat] for cat in compared]))\n",
    "    compared_results.columns = list(compared.keys())\n",
    "    \n",
    "    #Set up the results \n",
    "    results = fixed_results.to_frame().T\n",
    "    results['key'] = 0 \n",
    "    compared_results['key'] = 0\n",
    "    results = results.merge(compared_results, on='key', how='inner')\n",
    "    results.drop('key', axis='columns', inplace=True)\n",
    "    \n",
    "    return results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-15T02:19:51.132540Z",
     "start_time": "2020-06-15T02:19:51.099309Z"
    }
   },
   "outputs": [],
   "source": [
    "def compute_results(algos, old_resdf, orig_cols):\n",
    "    reddata = -1\n",
    "    loss_types = ['ACC']\n",
    "    fairness_types = ['DP', 'EOP', 'CAL']\n",
    "    sens_atts = {'adult':['race'], \\\n",
    "                 'german':['Personal']}     \n",
    "    \n",
    "    resdf = old_resdf.copy()\n",
    "    \n",
    "    #Get All The Results Columns of Interest: \n",
    "    res_cols = []\n",
    "    for al in algos.keys():\n",
    "        for m in ['train', 'test']:\n",
    "            for l in loss_types:\n",
    "                res_cols.append('{}-{}_error-{}'.format(al, m, l))\n",
    "            for f in fairness_types:\n",
    "                res_cols.append('{}-{}_fairness-{}'.format(al, m, f)) \n",
    "    for col in res_cols:  #Add cols to resultsdf\n",
    "        resdf[col] = np.nan\n",
    "    \n",
    "    \n",
    "    for al in algos.keys():  #Enumerate through algos     \n",
    "        for resid, row in resdf.iterrows():\n",
    "            algo_rescols = [c for c in res_cols if al in c]\n",
    "            if row[algo_rescols].isnull().all():   #Check if merics for row already been computed \n",
    "                \n",
    "                #Get entry of real dataset correpsonding to row \n",
    "                rel = df_subset(algos[al]['params'], row[orig_cols])  #Get row-associated entry in param dframe\n",
    "                assert rel.shape[0] <= 1 #Guarentee just one (Excluding multi-index mappings)\n",
    "                if rel.shape[0] == 0: \n",
    "                    continue\n",
    "                \n",
    "                alldata, all_y_all, d_atts = dp.data_loader(get_dset_fname(row['Dataset'], basedir), \\\n",
    "                                                              proc_fteng(row['Fteng']), \\\n",
    "                                                              dsize=reddata, \\\n",
    "                                                              bin=row['Bin'])\n",
    "                #Split data\n",
    "                train_data, train_y_all, d_atts, _, _, test_data, test_y_all = dp.train_val_test_split(\\\n",
    "                                                                          alldata, all_y_all, d_atts, test=row['TestSet'])\n",
    "                \n",
    "                #Compute Predictions  \n",
    "                if al == 'icp':\n",
    "                    model = models.InvariantCausalPrediction() \n",
    "                    learned_model = [pd.read_pickle(join(res_dir, rel.loc[rel.index[0], 'coeffs']))]\n",
    "                    \n",
    "                       \n",
    "                    train_predictions = model.predict(train_data, *learned_model)\n",
    "                    test_predictions = model.predict(test_data, *learned_model)\n",
    "\n",
    "                elif (al == 'irm') or (al == 'linear_irm'):\n",
    "                    if (al == 'irm'):\n",
    "                        model = models.InvariantRiskMinimization()\n",
    "                        try:\n",
    "                            learned_model = [torch.load(join(res_dir, rel.loc[rel.index[0], 'phi']))]\n",
    "                        except:\n",
    "                            import pdb; pdb.set_trace()\n",
    "                    elif (al == 'linear_irm'):\n",
    "                        model = models.LinearInvariantRiskMinimization()\n",
    "                        try:\n",
    "                            learned_model = [torch.load(join(res_dir, rel.loc[rel.index[0], 'phi']))]\n",
    "                        except:\n",
    "                            import pdb; pdb.set_trace()\n",
    "                    \n",
    "       \n",
    "                    train_predictions = model.predict(train_data.values, *learned_model, hid_layers=200)\n",
    "                    test_predictions = model.predict(test_data.values, *learned_model, hid_layers=200)                \n",
    "\n",
    "                elif al == 'linreg':\n",
    "                    model = models.Linear()\n",
    "                    learned_model = [pd.read_pickle(join(res_dir, rel.loc[rel.index[0], 'regressors']))]\n",
    "                    \n",
    "                    train_predictions = model.predict(train_data, *learned_model)   \n",
    "                    test_predictions = model.predict(test_data, *learned_model)  \n",
    "                \n",
    "                elif al == 'logreg':\n",
    "                    model = models.LogisticReg()\n",
    "                    learned_model = [pd.read_pickle(join(res_dir, rel.loc[rel.index[0], 'regressors']))]\n",
    "                    \n",
    "                    train_predictions = model.predict(train_data, *learned_model)   \n",
    "                    test_predictions = model.predict(test_data, *learned_model) \n",
    "                    \n",
    "                #Compute Metrics on Predictions \n",
    "                for ftype in fairness_types:\n",
    "                    for ltype in loss_types:\n",
    "                        for r in [['train', train_predictions, train_y_all, train_data], ['test', test_predictions, test_y_all, test_data]] :\n",
    "                            m, predictions, y_all, data = r[0], r[1], r[2], r[3]\n",
    "                        \n",
    "                            #Manage special case \n",
    "                            if predictions.empty:\n",
    "                                resdf.loc[resid, '{}-{}_error-{}'.format(al, m, ltype)] = 'NA'\n",
    "                                resdf.loc[resid, '{}-{}_fairness-{}'.format(al, m, ftype)] = 'NA'\n",
    "\n",
    "                            else:\n",
    "                                error = compute_loss(predictions.values, y_all.values, ltype=ltype)\n",
    "                                full_fair = 0\n",
    "                                for s in sens_atts[row['Dataset']]:\n",
    "                                    fairness =  fairness_dp(pred_binarize(predictions.values), y_all.values,\\\n",
    "                                                                data, {s:d_atts[s]}, ftype=ftype)\n",
    "                        \n",
    "                                    if not np.isnan(fairness):\n",
    "                                        full_fair += fairness/len(sens_atts[row['Dataset']])\n",
    "\n",
    "\n",
    "                                #Save computed values to resdf \n",
    "                                resdf.loc[resid, '{}-{}_error-{}'.format(al, m, ltype)] = error\n",
    "                                resdf.loc[resid, '{}-{}_fairness-{}'.format(al, m, ftype)] = full_fair\n",
    "                                \n",
    "    return resdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def split_data(row):\n",
    "    alldata, all_y_all, d_atts = dp.data_loader(get_dset_fname(row['Dataset'], basedir), \\\n",
    "                                                              proc_fteng(row['Fteng']), \\\n",
    "                                                              dsize=-1, \\\n",
    "                                                              bin=row['Bin'])\n",
    "    assert 'Val' not in row.index\n",
    "    train_data, train_labels, d_atts, val_data, val_labels, test_data, test_labels = \\\n",
    "         dp.train_val_test_split(alldata, all_y_all, d_atts, val=0.2, test=row['TestSet'], seed=row['Seed'])\n",
    "    \n",
    "    return train_data, train_labels, val_data, val_labels, test_data, test_labels\n",
    "        \n",
    "\n",
    "def compute_hyperparameters(true_resdf):\n",
    "    def compute_irm_loss(model, logits, labels, pen_reg):\n",
    "        logits, labels = make_tensor(logits.values), make_tensor(labels.values)\n",
    "        loss = model.mean_nll(logits, labels)\n",
    "        pen = model.penalty(logits, labels)\n",
    "        return (loss + (pen_reg * pen)).detach().numpy()\n",
    "    def compute_linreg_loss(logits, labels, weight, lam):\n",
    "        return ((logits - labels) ** 2).mean() + (weight * lam)\n",
    "  \n",
    "    \n",
    "    \n",
    "    resdf = true_resdf.copy(deep=True)\n",
    "    resdf['training_loss'] = np.nan\n",
    "    resdf['validation_loss'] = np.nan\n",
    "                                                                               \n",
    "    for resid, row in resdf.iterrows():\n",
    "        \n",
    "        #Load the data\n",
    "        train_data, train_labels, val_data, val_labels, _, _ = split_data(row)\n",
    "        \n",
    "        if (row['Algo'] == 'irm') or (row['Algo'] == 'linear_irm') :                                                                         \n",
    "            #Load the model\n",
    "            if (row['Algo'] == 'irm'):\n",
    "                try:\n",
    "                    src = models.InvariantRiskMinimization()\n",
    "                    params = torch.load(row['phi'])\n",
    "                except:\n",
    "                    resdf.drop(resid)\n",
    "                    continue\n",
    "                                      \n",
    "            elif (row['Algo'] == 'linear_irm'):\n",
    "                try:\n",
    "                    src = models.LinearInvariantRiskMinimization()\n",
    "                    params = torch.load(row['phi'])\n",
    "                except:\n",
    "                    resdf.drop(resid)\n",
    "                    continue\n",
    "                     \n",
    "            train_logits = src.predict(train_data.values, params, hid_layers=row['HidLayers'])\n",
    "            train_loss = compute_irm_loss(src, train_logits, \\\n",
    "                                      train_labels, row['PenWeight'])\n",
    "            val_logits = src.predict(val_data.values, params, hid_layers=row['HidLayers'])\n",
    "            val_loss = compute_irm_loss(src, val_logits, \\\n",
    "                                      val_labels, row['PenWeight'])\n",
    "            \n",
    "        elif (row['Algo'] == 'linreg'):\n",
    "            src = models.Linear()\n",
    "            coeffs = pd.read_pickle(row['regressors'])\n",
    "            weight = src.get_weight_norm(coeffs)\n",
    "            \n",
    "            train_logits = src.predict(train_data, coeffs)\n",
    "            train_loss = compute_linreg_loss(train_logits.values, train_labels.values, weight, row['Reg'])\n",
    "            val_logits = src.predict(val_data, coeffs)\n",
    "            val_loss = compute_linreg_loss(val_logits.values, val_labels.values, weight, row['Reg'])\n",
    "              \n",
    "        elif (row['Algo'] == 'logreg'):\n",
    "            src = models.LogisticReg()\n",
    "            coeffs = pd.read_pickle(row['regressors'])\n",
    "            weight = src.get_weight_norm(coeffs)\n",
    "            \n",
    "            train_logits = src.predict(train_data, coeffs)\n",
    "            train_loss = compute_linreg_loss(train_logits.values, train_labels.values, weight, row['Reg'])\n",
    "            val_logits = src.predict(val_data, coeffs)\n",
    "            val_loss = compute_linreg_loss(val_logits.values, val_labels.values, weight, row['Reg'])\n",
    "                                                                               \n",
    "        resdf.loc[resid, 'training_loss'] = train_loss    \n",
    "        resdf.loc[resid, 'validation_loss'] = val_loss\n",
    "    return resdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tuning_algo = 'linear-irm'\n",
    "res = compute_hyperparameters(invariance_algos[tuning_algo]['params'])\n",
    "\n",
    "if (tuning_algo == 'irm') or (tuning_algo == 'linear-irm'):\n",
    "    res.drop('phi', axis=1, inplace=True)\n",
    "elif (tuning_algo == 'linreg') or (tuning_algo == 'logreg'):\n",
    "    res.drop('regressors', axis=1, inplace=True)\n",
    "else: \n",
    "    raise Exception('Unimplemented Algo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "adult = res[res['Dataset'] == 'adult']\n",
    "at = adult.sort_values(by=['training_loss'])\n",
    "av = adult.sort_values(by=['validation_loss'])\n",
    "\n",
    "german = res[res['Dataset'] == 'german']\n",
    "gt = german.sort_values(by=['training_loss'])\n",
    "gv = german.sort_values(by=['validation_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "drop_cols = ['Algo', 'Fteng', 'Dataset', 'ReduceDsize', 'Bin', 'Eq_Estrat', 'Envs']  # ['Algo', 'Fteng', 'Dataset', 'ReduceDsize', 'Bin']\n",
    "view_cols = [\"TestSet\", 'LR', 'N_Iterations', 'PenWeight', 'HidLayers']  # [\"TestSet\", 'Reg']\n",
    "\n",
    "tmp = av.drop(drop_cols, axis=1)\n",
    "tmp = av.groupby([\"TestSet\", 'Reg'])[['training_loss', 'validation_loss']].mean()\n",
    "tmp.head(200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Evaluating on Invariance Algorithms "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-14T02:37:28.443889Z",
     "start_time": "2020-06-14T02:37:28.421653Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "invar_FIXED = [['Dataset', 'adult'], \\\n",
    "               ['ReduceDsize', 10000], \\\n",
    "               ['Eq_Estrat', -1]] \n",
    "\n",
    "invar_COMPARED =  {'Envs':['workclass', 'native-country'], \\\n",
    "                   'Seed':[147, 256, 304],\n",
    "                   'Fteng':['1', '12'], \\\n",
    "                   'Bin':[1]}\n",
    "\n",
    "invar_orig_cols = [a[0] for a in invar_FIXED] + list(invar_COMPARED.keys()) + ['TestSet']\n",
    "orig_invar_results = generate_all_existing_results(invar_orig_cols, \\\n",
    "                                             [invariance_algos[a]['params'] for a in list(invariance_algos.keys())])    \n",
    "#invar_results = generate_results(invar_FIXED, invar_COMPARED)\n",
    "\n",
    "# invar_results = invar_results[invar_results['Seed'] == 1000]\n",
    "orig_invar_results.head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-14T01:11:34.878718Z",
     "start_time": "2020-06-14T01:11:34.876019Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# ##TMPPPPPPPPPP\n",
    "\n",
    "# a = invariance_algos['linear_irm']['params']\n",
    "# invariance_algos['linear_irm']['params'] = a[(a['Seed'] == 1000) & (a['LR'] == 0.01) & (a['N_Iterations'] == 1000) \\\n",
    "#                                             & (a['PenWeight'] == 1000) & (a['HidLayers'] == 100)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-14T02:38:09.786801Z",
     "start_time": "2020-06-14T02:37:40.940890Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "invar_results = compute_results(invariance_algos, orig_invar_results, invar_orig_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-14T02:38:10.153232Z",
     "start_time": "2020-06-14T02:38:10.132358Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pd.options.display.max_colwidth = 4000\n",
    "invar_results.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating on Non-Invariance Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-15T02:19:22.856071Z",
     "start_time": "2020-06-15T02:19:22.836537Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>ReduceDsize</th>\n",
       "      <th>Bin</th>\n",
       "      <th>Fteng</th>\n",
       "      <th>Seed</th>\n",
       "      <th>TestSet</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>adult</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>52</td>\n",
       "      <td>workclass_DUMmY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>adult</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>52</td>\n",
       "      <td>native-country_DUMmY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>adult</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>52</td>\n",
       "      <td>relationship_DUMmY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>german</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>52</td>\n",
       "      <td>Purpose_DUMmY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>german</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>52</td>\n",
       "      <td>Housing_DUMmY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Dataset ReduceDsize Bin Fteng Seed               TestSet\n",
       "Id                                                         \n",
       "0    adult          -1   0    -1   52       workclass_DUMmY\n",
       "1    adult          -1   0    -1   52  native-country_DUMmY\n",
       "2    adult          -1   0    -1   52    relationship_DUMmY\n",
       "3   german          -1   0    -1   52         Purpose_DUMmY\n",
       "4   german          -1   0    -1   52         Housing_DUMmY"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var_FIXED = [['Dataset', 'adult'], \\\n",
    "               ['ReduceDsize', 10000], \\\n",
    "               ['Bin', 1]] \n",
    "\n",
    "var_COMPARED =  {'Fteng':['1', '12'], \\\n",
    "                 'Seed':[147, 256, 304]}\n",
    "\n",
    "var_orig_cols = [a[0] for a in var_FIXED] + list(var_COMPARED.keys()) + ['TestSet']\n",
    "orig_var_results = generate_all_existing_results(var_orig_cols, \\\n",
    "                                             [non_invariance_algos[a]['params'] for a in list(non_invariance_algos.keys())]) \n",
    "# var_results = generate_results(var_FIXED, var_COMPARED)\n",
    "\n",
    "orig_var_results.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-15T02:20:20.929002Z",
     "start_time": "2020-06-15T02:19:53.476052Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45086, 91)\n",
      "(43696, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/RobertAdragna/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:18: UserWarning: Using a target size (torch.Size([43696, 1])) that is different to the input size (torch.Size([43696])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(43696, 1)\n",
      "(1390, 1)\n",
      "(1390, 1)\n",
      "(43696, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/RobertAdragna/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:18: UserWarning: Using a target size (torch.Size([1390, 1])) that is different to the input size (torch.Size([1390])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(43696, 1)\n",
      "(1390, 1)\n",
      "(1390, 1)\n",
      "(43696, 1)\n",
      "(43696, 1)\n",
      "(1390, 1)\n",
      "(1390, 1)\n",
      "(45086, 91)\n",
      "(45060, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/RobertAdragna/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:18: UserWarning: Using a target size (torch.Size([45060, 1])) that is different to the input size (torch.Size([45060])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45060, 1)\n",
      "(26, 1)\n",
      "(26, 1)\n",
      "(45060, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/RobertAdragna/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:18: UserWarning: Using a target size (torch.Size([26, 1])) that is different to the input size (torch.Size([26])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45060, 1)\n",
      "(26, 1)\n",
      "(26, 1)\n",
      "(45060, 1)\n",
      "(45060, 1)\n",
      "(26, 1)\n",
      "(26, 1)\n",
      "(45086, 91)\n",
      "(26472, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/RobertAdragna/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:18: UserWarning: Using a target size (torch.Size([26472, 1])) that is different to the input size (torch.Size([26472])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26472, 1)\n",
      "(18614, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/RobertAdragna/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:18: UserWarning: Using a target size (torch.Size([18614, 1])) that is different to the input size (torch.Size([18614])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18614, 1)\n",
      "(26472, 1)\n",
      "(26472, 1)\n",
      "(18614, 1)\n",
      "(18614, 1)\n",
      "(26472, 1)\n",
      "(26472, 1)\n",
      "(18614, 1)\n",
      "(18614, 1)\n",
      "(988, 34)\n",
      "(754, 1)\n",
      "(754, 1)\n",
      "(234, 1)\n",
      "(234, 1)\n",
      "(754, 1)\n",
      "(754, 1)\n",
      "(234, 1)\n",
      "(234, 1)\n",
      "(754, 1)\n",
      "(754, 1)\n",
      "(234, 1)\n",
      "(234, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/RobertAdragna/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:18: UserWarning: Using a target size (torch.Size([754, 1])) that is different to the input size (torch.Size([754])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "/Users/RobertAdragna/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:18: UserWarning: Using a target size (torch.Size([234, 1])) that is different to the input size (torch.Size([234])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(988, 34)\n",
      "(809, 1)\n",
      "(809, 1)\n",
      "(179, 1)\n",
      "(179, 1)\n",
      "(809, 1)\n",
      "(809, 1)\n",
      "(179, 1)\n",
      "(179, 1)\n",
      "(809, 1)\n",
      "(809, 1)\n",
      "(179, 1)\n",
      "(179, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/RobertAdragna/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:18: UserWarning: Using a target size (torch.Size([809, 1])) that is different to the input size (torch.Size([809])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "/Users/RobertAdragna/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:18: UserWarning: Using a target size (torch.Size([179, 1])) that is different to the input size (torch.Size([179])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n"
     ]
    }
   ],
   "source": [
    "var_results = compute_results(non_invariance_algos, orig_var_results, var_orig_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-15T02:22:29.854939Z",
     "start_time": "2020-06-15T02:22:29.836561Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>ReduceDsize</th>\n",
       "      <th>Bin</th>\n",
       "      <th>Fteng</th>\n",
       "      <th>Seed</th>\n",
       "      <th>TestSet</th>\n",
       "      <th>linreg-train_error-ACC</th>\n",
       "      <th>linreg-train_fairness-DP</th>\n",
       "      <th>linreg-train_fairness-EOP</th>\n",
       "      <th>linreg-train_fairness-CAL</th>\n",
       "      <th>linreg-test_error-ACC</th>\n",
       "      <th>linreg-test_fairness-DP</th>\n",
       "      <th>linreg-test_fairness-EOP</th>\n",
       "      <th>linreg-test_fairness-CAL</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>adult</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>52</td>\n",
       "      <td>workclass_DUMmY</td>\n",
       "      <td>0.671958</td>\n",
       "      <td>0.202992</td>\n",
       "      <td>0.404121</td>\n",
       "      <td>0.151672</td>\n",
       "      <td>0.562679</td>\n",
       "      <td>0.378427</td>\n",
       "      <td>0.688473</td>\n",
       "      <td>0.342465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>adult</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>52</td>\n",
       "      <td>native-country_DUMmY</td>\n",
       "      <td>0.665347</td>\n",
       "      <td>0.217094</td>\n",
       "      <td>0.406197</td>\n",
       "      <td>0.164073</td>\n",
       "      <td>0.642012</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>adult</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>52</td>\n",
       "      <td>relationship_DUMmY</td>\n",
       "      <td>0.870632</td>\n",
       "      <td>0.039946</td>\n",
       "      <td>0.144541</td>\n",
       "      <td>0.027652</td>\n",
       "      <td>0.537267</td>\n",
       "      <td>0.150493</td>\n",
       "      <td>0.226601</td>\n",
       "      <td>0.124686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>german</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>52</td>\n",
       "      <td>Purpose_DUMmY</td>\n",
       "      <td>0.645579</td>\n",
       "      <td>0.234262</td>\n",
       "      <td>0.125865</td>\n",
       "      <td>0.211262</td>\n",
       "      <td>0.584886</td>\n",
       "      <td>0.129931</td>\n",
       "      <td>0.110048</td>\n",
       "      <td>0.140645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>german</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>52</td>\n",
       "      <td>Housing_DUMmY</td>\n",
       "      <td>0.640148</td>\n",
       "      <td>0.138253</td>\n",
       "      <td>0.043706</td>\n",
       "      <td>0.087629</td>\n",
       "      <td>0.574857</td>\n",
       "      <td>0.150439</td>\n",
       "      <td>0.033929</td>\n",
       "      <td>0.441788</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Dataset ReduceDsize Bin Fteng Seed               TestSet  \\\n",
       "Id                                                            \n",
       "0    adult          -1   0    -1   52       workclass_DUMmY   \n",
       "1    adult          -1   0    -1   52  native-country_DUMmY   \n",
       "2    adult          -1   0    -1   52    relationship_DUMmY   \n",
       "3   german          -1   0    -1   52         Purpose_DUMmY   \n",
       "4   german          -1   0    -1   52         Housing_DUMmY   \n",
       "\n",
       "    linreg-train_error-ACC  linreg-train_fairness-DP  \\\n",
       "Id                                                     \n",
       "0                 0.671958                  0.202992   \n",
       "1                 0.665347                  0.217094   \n",
       "2                 0.870632                  0.039946   \n",
       "3                 0.645579                  0.234262   \n",
       "4                 0.640148                  0.138253   \n",
       "\n",
       "    linreg-train_fairness-EOP  linreg-train_fairness-CAL  \\\n",
       "Id                                                         \n",
       "0                    0.404121                   0.151672   \n",
       "1                    0.406197                   0.164073   \n",
       "2                    0.144541                   0.027652   \n",
       "3                    0.125865                   0.211262   \n",
       "4                    0.043706                   0.087629   \n",
       "\n",
       "    linreg-test_error-ACC  linreg-test_fairness-DP  linreg-test_fairness-EOP  \\\n",
       "Id                                                                             \n",
       "0                0.562679                 0.378427                  0.688473   \n",
       "1                0.642012                 0.000000                  0.000000   \n",
       "2                0.537267                 0.150493                  0.226601   \n",
       "3                0.584886                 0.129931                  0.110048   \n",
       "4                0.574857                 0.150439                  0.033929   \n",
       "\n",
       "    linreg-test_fairness-CAL  \n",
       "Id                            \n",
       "0                   0.342465  \n",
       "1                   0.000000  \n",
       "2                   0.124686  \n",
       "3                   0.140645  \n",
       "4                   0.441788  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.options.display.max_colwidth = 400\n",
    "var_results.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-14T01:22:34.950441Z",
     "start_time": "2020-06-14T01:22:34.946094Z"
    }
   },
   "outputs": [],
   "source": [
    "non_invariance_algos.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save To Excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-15T02:23:42.117170Z",
     "start_time": "2020-06-15T02:23:41.626648Z"
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/RobertAdragna/Documents/School/Fourth_Year/ESC499-Thesis/codebases/causal_discovery/results/0610_baseline_adultgerman/testing/0610_baseline_adultgerman/testing_results.xlsx'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-947e4891ff02>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mexcel_fname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'{}_results.xlsx'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mvar_results\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_excel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetcwd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexcel_fname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mto_excel\u001b[0;34m(self, excel_writer, sheet_name, na_rep, float_format, columns, header, index, index_label, startrow, startcol, engine, merge_cells, encoding, inf_rep, verbose, freeze_panes)\u001b[0m\n\u001b[1;32m   2125\u001b[0m         formatter.write(excel_writer, sheet_name=sheet_name, startrow=startrow,\n\u001b[1;32m   2126\u001b[0m                         \u001b[0mstartcol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstartcol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfreeze_panes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfreeze_panes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2127\u001b[0;31m                         engine=engine)\n\u001b[0m\u001b[1;32m   2128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2129\u001b[0m     def to_json(self, path_or_buf=None, orient=None, date_format=None,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/formats/excel.py\u001b[0m in \u001b[0;36mwrite\u001b[0;34m(self, writer, sheet_name, startrow, startcol, freeze_panes, engine)\u001b[0m\n\u001b[1;32m    662\u001b[0m                            freeze_panes=freeze_panes)\n\u001b[1;32m    663\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mneed_save\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 664\u001b[0;31m             \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/excel.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1950\u001b[0m         \"\"\"\n\u001b[1;32m   1951\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1952\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1953\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1954\u001b[0m     def write_cells(self, cells, sheet_name=None, startrow=0, startcol=0,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/xlsxwriter/workbook.py\u001b[0m in \u001b[0;36mclose\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    302\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileclosed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileclosed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 304\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_store_workbook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    305\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mset_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/xlsxwriter/workbook.py\u001b[0m in \u001b[0;36m_store_workbook\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    650\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    651\u001b[0m         xlsx_file = ZipFile(self.filename, \"w\", compression=ZIP_DEFLATED,\n\u001b[0;32m--> 652\u001b[0;31m                             allowZip64=self.allow_zip64)\n\u001b[0m\u001b[1;32m    653\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    654\u001b[0m         \u001b[0;31m# Add XML sub-files to the Zip file with their Excel filename.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/zipfile.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, file, mode, compression, allowZip64, compresslevel)\u001b[0m\n\u001b[1;32m   1202\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1203\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1204\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilemode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1205\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1206\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mfilemode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodeDict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/RobertAdragna/Documents/School/Fourth_Year/ESC499-Thesis/codebases/causal_discovery/results/0610_baseline_adultgerman/testing/0610_baseline_adultgerman/testing_results.xlsx'"
     ]
    }
   ],
   "source": [
    "excel_fname = '{}_results.xlsx'.format(res_dir)\n",
    "var_results.to_excel(join(join(os.getcwd(), res_dir), excel_fname))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
