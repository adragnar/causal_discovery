{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-10T18:24:42.748349Z",
     "start_time": "2020-06-10T18:24:42.742296Z"
    }
   },
   "outputs": [],
   "source": [
    "import copy \n",
    "import os \n",
    "from os.path import join\n",
    "import shutil\n",
    "import itertools\n",
    "from collections import Counter\n",
    "import json\n",
    "import pickle\n",
    "import pprint\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pprint\n",
    "import torch \n",
    "import torch.nn.functional as F \n",
    "import math \n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "plt.rcParams['figure.figsize'] = [6, 8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-10T18:24:49.737754Z",
     "start_time": "2020-06-10T18:24:43.114593Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "basedir = '/Users/RobertAdragna/Documents/School/Fourth_Year/ESC499-Thesis/codebases/causal_discovery'\n",
    "sys.path.append(basedir)\n",
    "\n",
    "import data_processing as dp \n",
    "import environment_processing as eproc \n",
    "import models \n",
    "from utils import proc_fteng, make_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-10T18:24:49.776270Z",
     "start_time": "2020-06-10T18:24:49.771689Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.DS_Store', '.ipynb_checkpoints', '0525_smallsample', '0531_allgerman', '0602_validation', '0603_validation', '0607_adult', '0607_german', '0607_hyperparam_test', '0609_fulllinreg_hyperparam', '__pycache__', 'Hyperparameters.ipynb', 'latex_results', 'old_formatting', 'prediction.ipynb', 'real', 'today']\n"
     ]
    }
   ],
   "source": [
    "print(os.listdir(os.getcwd()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-10T18:44:12.588149Z",
     "start_time": "2020-06-10T18:44:12.578793Z"
    }
   },
   "outputs": [],
   "source": [
    "res_dir = '0609_test'\n",
    "invariance_algos = {}   #'icp':{},\n",
    "non_invariance_algos = {'linreg':{}}\n",
    "\n",
    "for als in [invariance_algos, non_invariance_algos]:\n",
    "    for al in als.keys(): \n",
    "        als[al]['expdir'] = join(join(join(os.getcwd(), res_dir), al), 'causal_discovery')\n",
    "        als[al]['processed_dir'] = join(join(join(os.getcwd(), res_dir), al), 'processed_results')\n",
    "        als[al]['params'] = pd.read_pickle(join(join(join(os.getcwd(), res_dir), al), '{}_paramfile.pkl'.format(al)))\n",
    "\n",
    "        if not os.path.exists(als[al]['processed_dir']):\n",
    "            raise Exception('Directory has not yet been processed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-10T18:44:16.701445Z",
     "start_time": "2020-06-10T18:44:16.688086Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Algo</th>\n",
       "      <th>Fteng</th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Seed</th>\n",
       "      <th>ReduceDsize</th>\n",
       "      <th>Bin</th>\n",
       "      <th>TestSet</th>\n",
       "      <th>linregressors</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>linreg</td>\n",
       "      <td>-1</td>\n",
       "      <td>german</td>\n",
       "      <td>52</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>Purpose_DUMmY</td>\n",
       "      <td>/Users/RobertAdragna/Documents/School/Fourth_Y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>linreg</td>\n",
       "      <td>-1</td>\n",
       "      <td>german</td>\n",
       "      <td>52</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>Housing_DUMmY</td>\n",
       "      <td>/Users/RobertAdragna/Documents/School/Fourth_Y...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Algo Fteng Dataset Seed ReduceDsize Bin        TestSet  \\\n",
       "Id                                                             \n",
       "3   linreg    -1  german   52          -1   0  Purpose_DUMmY   \n",
       "4   linreg    -1  german   52          -1   0  Housing_DUMmY   \n",
       "\n",
       "                                        linregressors  \n",
       "Id                                                     \n",
       "3   /Users/RobertAdragna/Documents/School/Fourth_Y...  \n",
       "4   /Users/RobertAdragna/Documents/School/Fourth_Y...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_invariance_algos['linreg']['params'].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-10T18:25:14.890980Z",
     "start_time": "2020-06-10T18:25:14.870820Z"
    }
   },
   "outputs": [],
   "source": [
    "def pred_binarize(v):\n",
    "    '''Convert all values to 0 if <0.5, 1 otherwise'''\n",
    "    def thresh(x):\n",
    "        if (x >= 0.5): return 1 \n",
    "        else: return 0\n",
    "    print(v.shape)\n",
    "    return np.apply_along_axis(thresh, 1, v)\n",
    "    \n",
    "        \n",
    "def compute_loss(pred, ground, ltype='MSE'):\n",
    "    '''Compute loss between two prediction vectors'''\n",
    "\n",
    "    \n",
    "    if ltype == 'MSE':\n",
    "        return F.mse_loss(torch.tensor(pred).float(), torch.tensor(ground).float()).numpy()\n",
    "    if ltype == 'ACC':\n",
    "        pred = pred_binarize(pred) \n",
    "        return 1 - F.mse_loss(torch.tensor(pred).float(), torch.tensor(ground).float()).numpy()\n",
    "    \n",
    "def fairness_dp(pred, ground, d, patts, ftype='DP'):\n",
    "    '''Compute demographic aparity wrt data\n",
    "    :param pred: vector, binary entries (np[float])\n",
    "    :param ground: vector, binary entries (np[float])\n",
    "    :param d: dataset (pandas df)\n",
    "    :param patt: datts dict {cat:[all orig columns]}'''\n",
    "    \n",
    "    def avg_diff_scores(p):\n",
    "        ''' Given a dictionary of scores for different sensitive attributes p.keys, \\ \n",
    "            return the average difference between these values '''\n",
    "        na = len(p.keys())\n",
    "        if na <= 1:  #Error checking\n",
    "            return np.nan\n",
    "        \n",
    "        n_combos = math.factorial(na)/ (2 * math.factorial(na - 2))\n",
    "        \n",
    "        tot = 0\n",
    "        for pair in itertools.combinations(list(p.keys()), 2): \n",
    "            tot += abs(p[pair[0]] - p[pair[1]])\n",
    "        \n",
    "        return float(tot/na)\n",
    "\n",
    "    \n",
    "    #Get the protected attribute columns \n",
    "    assert len(patts.keys()) == 1\n",
    "    protected = [patts[cat] for cat in patts.keys()][0]\n",
    "    \n",
    "    probs = {}   \n",
    "    #Compute p(y_hat=1 | a, y)  Va  (demographic parity)\n",
    "\n",
    "    for aval in protected: \n",
    "        if '_DUMmY' in aval:\n",
    "            subpop = (d[[a for a in protected if '_DUMmY' not in a]] == 0).all(1).values.squeeze()\n",
    "        else:\n",
    "            subpop = (d[aval] == 1).values.squeeze()\n",
    "        \n",
    "        #Make sure that there are samples in the group of interest \n",
    "        if (subpop.sum() == 0) or ((subpop & (ground == 1).squeeze()).sum() == 0):\n",
    "            continue\n",
    "        \n",
    "        #Compute fairness\n",
    "        if ftype == 'DP': \n",
    "            probs[aval] = pred[subpop].sum() / len(pred[subpop])\n",
    "        \n",
    "        elif ftype == 'EOP':\n",
    "            probs[aval] = pred[subpop & (ground == 1).squeeze()].sum() / len(pred[subpop & (ground == 1).squeeze()])\n",
    "        \n",
    "        elif ftype == 'CAL':\n",
    "            probs[aval] = ground[subpop & (pred == 1).squeeze()].sum() / len(ground[subpop])\n",
    "\n",
    "    return avg_diff_scores(probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-10T18:25:15.041910Z",
     "start_time": "2020-06-10T18:25:15.035824Z"
    }
   },
   "outputs": [],
   "source": [
    "def df_subset(df, subset):\n",
    "    '''Get a subset of df rows whose columns specified in subset equal their respective values\n",
    "    :param df: Dataframe (pandas)\n",
    "    :param subset: Series of col_name:value pairs (pandas series)\n",
    "    '''\n",
    "    new_df = df.copy(deep=True)\n",
    "    for col, val in pd.Series.iteritems(subset):\n",
    "        new_df = new_df[new_df[col] == val]\n",
    "    return new_df\n",
    "\n",
    "def get_dset_fname(dset, b):\n",
    "    if dset == 'adult':\n",
    "        datafname = join(join(b, 'data'), 'adult.csv')\n",
    "    elif dset == 'german':\n",
    "        datafname = join(join(b, 'data'), 'germanCredit.csv')\n",
    "    else:\n",
    "        raise Exception('Dataset unimplemented')\n",
    "    \n",
    "    return datafname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-10T18:25:15.205134Z",
     "start_time": "2020-06-10T18:25:15.195463Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_all_existing_results(allcols, ags):\n",
    "    ''' param allcols: A list of the features to be included\n",
    "        param ags: A list of paramdfs for each algorithm'''\n",
    "    add = pd.DataFrame()\n",
    "    for param_df in ags: \n",
    "        if add.empty:\n",
    "            add = param_df[allcols]\n",
    "        else:\n",
    "            add = add.append(param_df[allcols], ignore_index=True)\n",
    "    \n",
    "    uniq = np.logical_not(add.duplicated())\n",
    "    return add[uniq]\n",
    "    \n",
    "    \n",
    "def generate_results(fixed, compared): \n",
    "    '''\n",
    "    :param fixed: A list of tuples (pname, pval) that are fixed across exps\n",
    "    :param compared: A dictionary of pname:full range of possible values in experiment ''' \n",
    "    \n",
    "    fixed_results = pd.Series([np.nan]*len(fixed), index=[f[0] for f in fixed]) #  , index=fixed_cols) \n",
    "    for f in fixed:\n",
    "        fixed_results[f[0]] = f[1]\n",
    "    \n",
    "    #Set Up the Results Dataframe \n",
    "    compared_results = pd.DataFrame(itertools.product(*[compared[cat] for cat in compared]))\n",
    "    compared_results.columns = list(compared.keys())\n",
    "    \n",
    "    #Set up the results \n",
    "    results = fixed_results.to_frame().T\n",
    "    results['key'] = 0 \n",
    "    compared_results['key'] = 0\n",
    "    results = results.merge(compared_results, on='key', how='inner')\n",
    "    results.drop('key', axis='columns', inplace=True)\n",
    "    \n",
    "    return results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-10T18:25:15.477556Z",
     "start_time": "2020-06-10T18:25:15.451068Z"
    }
   },
   "outputs": [],
   "source": [
    "def compute_results(algos, resdf, orig_cols, from_scratch=False):\n",
    "    reddata = -1\n",
    "    loss_types = ['ACC']\n",
    "    fairness_types = ['DP', 'EOP', 'CAL']\n",
    "    sens_atts = {'adult':['race', 'gender', 'relationship'], \\\n",
    "                 'german':['Personal']}     \n",
    "    \n",
    "    #Get All The Results Columns of Interest: \n",
    "    res_cols = []\n",
    "    for al in algos.keys():\n",
    "        for m in ['train', 'test']:\n",
    "            for l in loss_types:\n",
    "                res_cols.append('{}-{}_error-{}'.format(al, m, l))\n",
    "            for f in fairness_types:\n",
    "                res_cols.append('{}-{}_fairness-{}'.format(al, m, f)) \n",
    "    for col in res_cols:  #Add cols to resultsdf\n",
    "        if (col not in list(resdf.columns)) or from_scratch:\n",
    "            resdf[col] = np.nan\n",
    "    \n",
    "    \n",
    "    for al in algos.keys():  #Enumerate through algos     \n",
    "        for resid, row in resdf.iterrows():\n",
    "            algo_rescols = [c for c in res_cols if al in c]\n",
    "            if row[algo_rescols].isnull().all():   #Check if merics for row already been computed \n",
    "                \n",
    "                #Get entry of real dataset correpsonding to row \n",
    "                rel = df_subset(algos[al]['params'], row[orig_cols])  #Get row-associated entry in param dframe\n",
    "                assert rel.shape[0] <= 1 #Guarentee just one (Excluding multi-index mappings)\n",
    "                if rel.shape[0] == 0: \n",
    "                    continue\n",
    "                \n",
    "                alldata, all_y_all, d_atts = dp.data_loader(get_dset_fname(row['Dataset'], basedir), \\\n",
    "                                                              proc_fteng(row['Fteng']), \\\n",
    "                                                              dsize=reddata, \\\n",
    "                                                              bin=row['Bin'])\n",
    "                #Split data\n",
    "                train_data, train_y_all, d_atts, _, _, test_data, test_y_all = dp.train_val_test_split(\\\n",
    "                                                                          alldata, all_y_all, d_atts, test=row['TestSet'])\n",
    "                \n",
    "                #Compute Predictions  \n",
    "                if al == 'icp':\n",
    "                    model = models.InvariantCausalPrediction() \n",
    "                    learned_model = [pd.read_pickle(rel.loc[rel.index[0], 'coeffs'])]\n",
    "                    \n",
    "                       \n",
    "                    train_predictions = model.predict(train_data, *learned_model)\n",
    "                    test_predictions = model.predict(test_data, *learned_model)\n",
    "\n",
    "                elif al == 'irm':\n",
    "                    model = models.InvariantRiskMinimization()\n",
    "                    try:\n",
    "                        learned_model = [torch.load(rel.loc[rel.index[0], 'phi'])]\n",
    "                    except:\n",
    "                        import pdb; pdb.set_trace()\n",
    "       \n",
    "                    train_predictions = model.predict(train_data.values, *learned_model, hid_layers=200)\n",
    "                    test_predictions = model.predict(test_data.values, *learned_model, hid_layers=200)                \n",
    "\n",
    "                elif al == 'linreg':\n",
    "                    model = models.Linear()\n",
    "                    learned_model = [pd.read_pickle(rel.loc[rel.index[0], 'linregressors'])]\n",
    "                    \n",
    "                    train_predictions = model.predict(train_data, *learned_model)   \n",
    "                    test_predictions = model.predict(test_data, *learned_model)  \n",
    "\n",
    "                    \n",
    "                #Compute Metrics on Predictions \n",
    "                for ftype in fairness_types:\n",
    "                    for ltype in loss_types:\n",
    "                        for r in [['train', train_predictions, train_y_all, train_data], ['test', test_predictions, test_y_all, test_data]] :\n",
    "                            m, predictions, y_all, data = r[0], r[1], r[2], r[3]\n",
    "                        \n",
    "                            #Manage special case \n",
    "                            if predictions.empty:\n",
    "                                resdf.loc[resid, '{}-{}_error-{}'.format(al, m, ltype)] = 'NA'\n",
    "                                resdf.loc[resid, '{}-{}_fairness-{}'.format(al, m, ftype)] = 'NA'\n",
    "\n",
    "                            else:\n",
    "                                error = compute_loss(predictions.values, y_all.values, ltype=ltype)\n",
    "                                full_fair= ''\n",
    "                                for s in sens_atts[row['Dataset']]:\n",
    "                                    fairness =  fairness_dp(pred_binarize(predictions.values), y_all.values,\\\n",
    "                                                            data, {s:d_atts[s]}, ftype=ftype)\n",
    "                                    full_fair = full_fair + ' {0}:{1:.3f} \\n'.format(s, fairness)\n",
    "\n",
    "\n",
    "                                #Save computed values to resdf \n",
    "                                resdf.loc[resid, '{}-{}_error-{}'.format(al, m, ltype)] = error\n",
    "                                resdf.loc[resid, '{}-{}_fairness-{}'.format(al, m, ftype)] = full_fair"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-10T18:25:17.471566Z",
     "start_time": "2020-06-10T18:25:17.451494Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def split_data(row):\n",
    "    alldata, all_y_all, d_atts = dp.data_loader(get_dset_fname(row['Dataset'], basedir), \\\n",
    "                                                              proc_fteng(row['Fteng']), \\\n",
    "                                                              dsize=-1, \\\n",
    "                                                              bin=row['Bin'])\n",
    "    assert 'Val' not in row.index\n",
    "    train_data, train_labels, d_atts, val_data, val_labels, test_data, test_labels = \\\n",
    "         dp.train_val_test_split(alldata, all_y_all, d_atts, val=0.2, test=row['TestSet'], seed=row['Seed'])\n",
    "    \n",
    "    return train_data, train_labels, val_data, val_labels, test_data, test_labels\n",
    "        \n",
    "\n",
    "def compute_hyperparameters(true_resdf):\n",
    "    def compute_irm_loss(model, logits, labels, pen_reg):\n",
    "        logits, labels = make_tensor(logits.values), make_tensor(labels.values)\n",
    "        loss = model.mean_nll(logits, labels)\n",
    "        pen = model.penalty(logits, labels)\n",
    "        return (loss + (pen_reg * pen)).detach().numpy()\n",
    "    def compute_linreg_loss(logits, labels, weight, lam):\n",
    "        return ((logits - labels) ** 2).mean() + (weight * lam)\n",
    "  \n",
    "    \n",
    "    \n",
    "    resdf = true_resdf.copy(deep=True)\n",
    "    resdf['training_loss'] = np.nan\n",
    "    resdf['validation_loss'] = np.nan\n",
    "                                                                               \n",
    "    for resid, row in resdf.iterrows():\n",
    "        \n",
    "        #Load the data\n",
    "        train_data, train_labels, val_data, val_labels, _, _ = split_data(row)\n",
    "        \n",
    "        if row['Algo'] == 'irm' :                                                                         \n",
    "            #Load the model\n",
    "            try:\n",
    "                src = models.InvariantRiskMinimization()\n",
    "                params = torch.load(row['phi'])\n",
    "            except:\n",
    "                resdf.drop(resid)\n",
    "                continue\n",
    "            train_logits = src.predict(train_data.values, params, hid_layers=row['HidLayers'])\n",
    "            train_loss = compute_irm_loss(src, train_logits, \\\n",
    "                                      train_labels, row['PenWeight'])\n",
    "            val_logits = src.predict(val_data.values, params, hid_layers=row['HidLayers'])\n",
    "            val_loss = compute_irm_loss(src, val_logits, \\\n",
    "                                      val_labels, row['PenWeight'])\n",
    "            \n",
    "        elif row['Algo'] == 'linreg':\n",
    "            src = models.Linear()\n",
    "            coeffs = pd.read_pickle(row['linregressors'])\n",
    "            weight = src.get_weight_norm(coeffs)\n",
    "            \n",
    "            train_logits = src.predict(train_data, coeffs)\n",
    "            train_loss = compute_linreg_loss(train_logits.values, train_labels.values, weight, row['Reg'])\n",
    "            val_logits = src.predict(val_data, coeffs)\n",
    "            val_loss = compute_linreg_loss(val_logits.values, val_labels.values, weight, row['Reg'])\n",
    "                                                                               \n",
    "        resdf.loc[resid, 'training_loss'] = train_loss    \n",
    "        resdf.loc[resid, 'validation_loss'] = val_loss\n",
    "    return resdf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Linreg Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-10T18:25:56.577075Z",
     "start_time": "2020-06-10T18:25:21.444080Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45086, 91)\n",
      "(45086, 91)\n",
      "(45086, 91)\n",
      "(45086, 91)\n",
      "(45086, 91)\n",
      "(45086, 91)\n",
      "(45086, 91)\n",
      "(45086, 91)\n",
      "(45086, 91)\n",
      "(45086, 91)\n",
      "(45086, 91)\n",
      "(45086, 91)\n",
      "(45086, 91)\n",
      "(45086, 91)\n",
      "(45086, 91)\n",
      "(45086, 91)\n",
      "(45086, 91)\n",
      "(45086, 91)\n",
      "(45086, 91)\n",
      "(45086, 91)\n",
      "(45086, 91)\n",
      "(45086, 91)\n",
      "(45086, 91)\n",
      "(45086, 91)\n",
      "(45086, 91)\n",
      "(45086, 91)\n",
      "(45086, 91)\n",
      "(45086, 91)\n",
      "(45086, 91)\n",
      "(45086, 91)\n",
      "(45086, 91)\n",
      "(45086, 91)\n",
      "(45086, 91)\n",
      "(45086, 91)\n",
      "(45086, 91)\n",
      "(45086, 91)\n",
      "(45086, 91)\n",
      "(45086, 91)\n",
      "(45086, 91)\n",
      "(45086, 91)\n",
      "(45086, 91)\n",
      "(45086, 91)\n",
      "(45086, 91)\n",
      "(45086, 91)\n",
      "(45086, 91)\n",
      "(45086, 91)\n",
      "(45086, 91)\n",
      "(45086, 91)\n",
      "(45086, 91)\n",
      "(45086, 91)\n",
      "(45086, 91)\n",
      "(45086, 91)\n",
      "(45086, 91)\n",
      "(45086, 91)\n",
      "(45086, 91)\n",
      "(45086, 91)\n",
      "(45086, 91)\n",
      "(45086, 91)\n",
      "(45086, 91)\n",
      "(45086, 91)\n",
      "(45086, 91)\n",
      "(45086, 91)\n",
      "(45086, 91)\n",
      "(45086, 91)\n",
      "(45086, 91)\n",
      "(45086, 91)\n",
      "(45086, 91)\n",
      "(45086, 91)\n",
      "(45086, 91)\n",
      "(45086, 91)\n",
      "(45086, 91)\n",
      "(45086, 91)\n",
      "(988, 34)\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'workclass'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-22c330e054c4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_hyperparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnon_invariance_algos\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'linreg'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'params'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'linregressors'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-8083abfb3442>\u001b[0m in \u001b[0;36mcompute_hyperparameters\u001b[0;34m(true_resdf)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;31m#Load the data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplit_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Algo'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'irm'\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-8083abfb3442>\u001b[0m in \u001b[0;36msplit_data\u001b[0;34m(row)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0;34m'Val'\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_atts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_labels\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m          \u001b[0mdp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_val_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malldata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_y_all\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_atts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'TestSet'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Seed'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/School/Fourth_Year/ESC499-Thesis/codebases/causal_discovery/data_processing.py\u001b[0m in \u001b[0;36mtrain_val_test_split\u001b[0;34m(data, labels, d_atts, val, test, seed)\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'_'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mevar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'_'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0me_ins_store\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meproc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_environments\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mevar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0md_atts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mevar\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m         \u001b[0mtest_ein\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me_ins_store\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'workclass'"
     ]
    }
   ],
   "source": [
    "res = compute_hyperparameters(non_invariance_algos['linreg']['params'])\n",
    "res.drop('linregressors', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-10T01:06:59.085562Z",
     "start_time": "2020-06-10T01:06:59.075652Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "adult = res[res['Dataset'] == 'adult']\n",
    "at = adult.sort_values(by=['training_loss'])\n",
    "av = adult.sort_values(by=['validation_loss'])\n",
    "\n",
    "german = res[res['Dataset'] == 'german']\n",
    "gt = adult.sort_values(by=['training_loss'])\n",
    "gv = adult.sort_values(by=['validation_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-10T01:07:45.723181Z",
     "start_time": "2020-06-10T01:07:45.706603Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "gv.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-10T01:07:22.792573Z",
     "start_time": "2020-06-10T01:07:22.773483Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tmp = gv.drop(['Algo', 'Fteng', 'Dataset', 'ReduceDsize', 'Bin'], axis=1)\n",
    "tmp = gv.groupby([\"TestSet\", 'Reg'])[['training_loss', 'validation_loss']].mean()\n",
    "tmp.head(200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## IRM Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-09T23:17:48.965865Z",
     "start_time": "2020-06-09T23:16:20.449Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "res = compute_hyperparameters(invariance_algos['irm']['params'])\n",
    "res.drop('phi', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-09T23:17:48.967504Z",
     "start_time": "2020-06-09T23:16:20.451Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "res.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-09T23:17:48.969297Z",
     "start_time": "2020-06-09T23:16:20.453Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# testing = res.groupby(['PenWeight', 'LR']).mean()\n",
    "# testing.head(10)\n",
    "t = res.sort_values(by=['training_loss'])\n",
    "v = res.sort_values(by=['validation_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-09T23:17:48.970994Z",
     "start_time": "2020-06-09T23:16:20.456Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "t.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-09T23:17:48.973055Z",
     "start_time": "2020-06-09T23:16:20.458Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "v.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-09T23:17:48.974781Z",
     "start_time": "2020-06-09T23:16:20.460Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "orig = ['Algo', 'Fteng', 'Dataset', \\\n",
    "                                'ReduceDsize', 'Bin', 'Eq_Estrat', \\\n",
    "                                'LR', 'N_Iterations', 'L2_WeightPen', \\\n",
    "                                'N_AnnealIter', 'PenWeight', 'HidLayers']\n",
    "final = pd.DataFrame(columns=(orig + ['training_loss', 'validation_loss']))\n",
    "i=0\n",
    "for resid, row in v.iterrows():\n",
    "    if (i < 500) and (row['Seed'] == 1000):  #and (row['Envs'] == ''):\n",
    "        tmp = df_subset(v, row[orig])\n",
    "        tmp = tmp.drop('Seed', axis=1)\n",
    "        tmp = tmp.drop('Envs', axis=1)\n",
    "        tmp = tmp.drop('TestSet', axis=1)\n",
    "        tmp.loc[resid, 'training_loss'] = tmp['training_loss'].mean()\n",
    "        tmp.loc[resid, 'validation_loss'] = tmp['validation_loss'].mean()\n",
    "        final = final.append(tmp.loc[resid])\n",
    "        i += 1\n",
    "final = final.sort_values(by=['validation_loss'])\n",
    "final = final.reset_index()\n",
    "final.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-09T23:17:48.976424Z",
     "start_time": "2020-06-09T23:16:20.463Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "final.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-09T23:17:48.978128Z",
     "start_time": "2020-06-09T23:16:20.465Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "this_orig = ['Algo', 'Fteng', 'Dataset', \\\n",
    "                                'ReduceDsize', 'Bin', 'Eq_Estrat', \\\n",
    "                                'LR', 'N_Iterations', 'L2_WeightPen', \\\n",
    "                                'N_AnnealIter', 'PenWeight', 'HidLayers']\n",
    "df_subset(final, final.loc[16][this_orig])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Evaluating on Invariance Algorithms "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-10T15:19:01.534236Z",
     "start_time": "2020-06-10T15:19:01.477490Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>ReduceDsize</th>\n",
       "      <th>Eq_Estrat</th>\n",
       "      <th>Envs</th>\n",
       "      <th>Seed</th>\n",
       "      <th>Fteng</th>\n",
       "      <th>Bin</th>\n",
       "      <th>TestSet</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>adult</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>workclass</td>\n",
       "      <td>52</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>workclass_DUMmY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>adult</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>native-country</td>\n",
       "      <td>52</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>native-country_DUMmY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>adult</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>relationship</td>\n",
       "      <td>52</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>relationship_DUMmY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>german</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>Purpose</td>\n",
       "      <td>52</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>Purpose_DUMmY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>german</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>Housing</td>\n",
       "      <td>52</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>Housing_DUMmY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Dataset ReduceDsize Eq_Estrat            Envs Seed Fteng Bin  \\\n",
       "Id                                                                \n",
       "0    adult          -1        -1       workclass   52    -1   0   \n",
       "1    adult          -1        -1  native-country   52    -1   0   \n",
       "2    adult          -1        -1    relationship   52    -1   0   \n",
       "3   german          -1        -1         Purpose   52    -1   0   \n",
       "4   german          -1        -1         Housing   52    -1   0   \n",
       "\n",
       "                 TestSet  \n",
       "Id                        \n",
       "0        workclass_DUMmY  \n",
       "1   native-country_DUMmY  \n",
       "2     relationship_DUMmY  \n",
       "3          Purpose_DUMmY  \n",
       "4          Housing_DUMmY  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "invar_FIXED = [['Dataset', 'adult'], \\\n",
    "               ['ReduceDsize', 10000], \\\n",
    "               ['Eq_Estrat', -1]] \n",
    "\n",
    "invar_COMPARED =  {'Envs':['workclass', 'native-country'], \\\n",
    "                   'Seed':[147, 256, 304],\n",
    "                   'Fteng':['1', '12'], \\\n",
    "                   'Bin':[1]}\n",
    "\n",
    "invar_orig_cols = [a[0] for a in invar_FIXED] + list(invar_COMPARED.keys()) + ['TestSet']\n",
    "invar_results = generate_all_existing_results(invar_orig_cols, \\\n",
    "                                             [invariance_algos[a]['params'] for a in list(invariance_algos.keys())])    \n",
    "#invar_results = generate_results(invar_FIXED, invar_COMPARED)\n",
    "\n",
    "invar_results.head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-10T16:25:46.671112Z",
     "start_time": "2020-06-10T16:25:11.505846Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45086, 91)\n",
      "(43696, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/RobertAdragna/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:18: UserWarning: Using a target size (torch.Size([43696, 1])) that is different to the input size (torch.Size([43696])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(43696, 1)\n",
      "(43696, 1)\n",
      "(43696, 1)\n",
      "(1390, 1)\n",
      "(1390, 1)\n",
      "(1390, 1)\n",
      "(1390, 1)\n",
      "(43696, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/RobertAdragna/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:18: UserWarning: Using a target size (torch.Size([1390, 1])) that is different to the input size (torch.Size([1390])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(43696, 1)\n",
      "(43696, 1)\n",
      "(43696, 1)\n",
      "(1390, 1)\n",
      "(1390, 1)\n",
      "(1390, 1)\n",
      "(1390, 1)\n",
      "(43696, 1)\n",
      "(43696, 1)\n",
      "(43696, 1)\n",
      "(43696, 1)\n",
      "(1390, 1)\n",
      "(1390, 1)\n",
      "(1390, 1)\n",
      "(1390, 1)\n",
      "(45086, 91)\n",
      "(45060, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/RobertAdragna/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:18: UserWarning: Using a target size (torch.Size([45060, 1])) that is different to the input size (torch.Size([45060])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45060, 1)\n",
      "(45060, 1)\n",
      "(45060, 1)\n",
      "(26, 1)\n",
      "(26, 1)\n",
      "(26, 1)\n",
      "(26, 1)\n",
      "(45060, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/RobertAdragna/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:18: UserWarning: Using a target size (torch.Size([26, 1])) that is different to the input size (torch.Size([26])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45060, 1)\n",
      "(45060, 1)\n",
      "(45060, 1)\n",
      "(26, 1)\n",
      "(26, 1)\n",
      "(26, 1)\n",
      "(26, 1)\n",
      "(45060, 1)\n",
      "(45060, 1)\n",
      "(45060, 1)\n",
      "(45060, 1)\n",
      "(26, 1)\n",
      "(26, 1)\n",
      "(26, 1)\n",
      "(26, 1)\n",
      "(45086, 91)\n",
      "(26472, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/RobertAdragna/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:18: UserWarning: Using a target size (torch.Size([26472, 1])) that is different to the input size (torch.Size([26472])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26472, 1)\n",
      "(26472, 1)\n",
      "(26472, 1)\n",
      "(18614, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/RobertAdragna/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:18: UserWarning: Using a target size (torch.Size([18614, 1])) that is different to the input size (torch.Size([18614])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18614, 1)\n",
      "(18614, 1)\n",
      "(18614, 1)\n",
      "(26472, 1)\n",
      "(26472, 1)\n",
      "(26472, 1)\n",
      "(26472, 1)\n",
      "(18614, 1)\n",
      "(18614, 1)\n",
      "(18614, 1)\n",
      "(18614, 1)\n",
      "(26472, 1)\n",
      "(26472, 1)\n",
      "(26472, 1)\n",
      "(26472, 1)\n",
      "(18614, 1)\n",
      "(18614, 1)\n",
      "(18614, 1)\n",
      "(18614, 1)\n",
      "(988, 34)\n",
      "(754, 1)\n",
      "(754, 1)\n",
      "(234, 1)\n",
      "(234, 1)\n",
      "(754, 1)\n",
      "(754, 1)\n",
      "(234, 1)\n",
      "(234, 1)\n",
      "(754, 1)\n",
      "(754, 1)\n",
      "(234, 1)\n",
      "(234, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/RobertAdragna/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:18: UserWarning: Using a target size (torch.Size([754, 1])) that is different to the input size (torch.Size([754])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "/Users/RobertAdragna/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:18: UserWarning: Using a target size (torch.Size([234, 1])) that is different to the input size (torch.Size([234])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(988, 34)\n",
      "(809, 1)\n",
      "(809, 1)\n",
      "(179, 1)\n",
      "(179, 1)\n",
      "(809, 1)\n",
      "(809, 1)\n",
      "(179, 1)\n",
      "(179, 1)\n",
      "(809, 1)\n",
      "(809, 1)\n",
      "(179, 1)\n",
      "(179, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/RobertAdragna/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:18: UserWarning: Using a target size (torch.Size([809, 1])) that is different to the input size (torch.Size([809])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "/Users/RobertAdragna/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:18: UserWarning: Using a target size (torch.Size([179, 1])) that is different to the input size (torch.Size([179])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n"
     ]
    }
   ],
   "source": [
    "compute_results(invariance_algos, invar_results, invar_orig_cols, from_scratch=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-10T16:25:55.585280Z",
     "start_time": "2020-06-10T16:25:55.565246Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>ReduceDsize</th>\n",
       "      <th>Eq_Estrat</th>\n",
       "      <th>Envs</th>\n",
       "      <th>Seed</th>\n",
       "      <th>Fteng</th>\n",
       "      <th>Bin</th>\n",
       "      <th>TestSet</th>\n",
       "      <th>irm-train_error-ACC</th>\n",
       "      <th>irm-train_fairness-DP</th>\n",
       "      <th>irm-train_fairness-EOP</th>\n",
       "      <th>irm-train_fairness-CAL</th>\n",
       "      <th>irm-test_error-ACC</th>\n",
       "      <th>irm-test_fairness-DP</th>\n",
       "      <th>irm-test_fairness-EOP</th>\n",
       "      <th>irm-test_fairness-CAL</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>adult</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>workclass</td>\n",
       "      <td>52</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>workclass_DUMmY</td>\n",
       "      <td>0.727994</td>\n",
       "      <td>race:0.034 \\n gender:0.016 \\n relationship:0.105 \\n</td>\n",
       "      <td>race:0.080 \\n gender:0.012 \\n relationship:0.207 \\n</td>\n",
       "      <td>race:0.031 \\n gender:0.018 \\n relationship:0.102 \\n</td>\n",
       "      <td>0.591752</td>\n",
       "      <td>race:0.163 \\n gender:0.021 \\n relationship:0.111 \\n</td>\n",
       "      <td>race:0.263 \\n gender:0.021 \\n relationship:0.385 \\n</td>\n",
       "      <td>race:0.145 \\n gender:0.021 \\n relationship:0.129 \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>adult</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>native-country</td>\n",
       "      <td>52</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>native-country_DUMmY</td>\n",
       "      <td>0.708622</td>\n",
       "      <td>race:0.092 \\n gender:0.037 \\n relationship:0.205 \\n</td>\n",
       "      <td>race:0.116 \\n gender:0.015 \\n relationship:0.128 \\n</td>\n",
       "      <td>race:0.070 \\n gender:0.031 \\n relationship:0.171 \\n</td>\n",
       "      <td>0.642012</td>\n",
       "      <td>race:nan \\n gender:0.023 \\n relationship:0.111 \\n</td>\n",
       "      <td>race:nan \\n gender:0.062 \\n relationship:0.333 \\n</td>\n",
       "      <td>race:nan \\n gender:0.023 \\n relationship:0.111 \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>adult</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>relationship</td>\n",
       "      <td>52</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>relationship_DUMmY</td>\n",
       "      <td>0.861698</td>\n",
       "      <td>race:0.037 \\n gender:0.010 \\n relationship:0.187 \\n</td>\n",
       "      <td>race:0.169 \\n gender:0.024 \\n relationship:0.131 \\n</td>\n",
       "      <td>race:0.023 \\n gender:0.007 \\n relationship:0.162 \\n</td>\n",
       "      <td>0.535234</td>\n",
       "      <td>race:0.085 \\n gender:nan \\n relationship:nan \\n</td>\n",
       "      <td>race:0.096 \\n gender:nan \\n relationship:nan \\n</td>\n",
       "      <td>race:0.084 \\n gender:nan \\n relationship:nan \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>german</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>Purpose</td>\n",
       "      <td>52</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>Purpose_DUMmY</td>\n",
       "      <td>0.432023</td>\n",
       "      <td>Personal:0.124 \\n</td>\n",
       "      <td>Personal:0.164 \\n</td>\n",
       "      <td>Personal:0.055 \\n</td>\n",
       "      <td>0.481591</td>\n",
       "      <td>Personal:0.345 \\n</td>\n",
       "      <td>Personal:0.345 \\n</td>\n",
       "      <td>Personal:0.234 \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>german</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>Housing</td>\n",
       "      <td>52</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>Housing_DUMmY</td>\n",
       "      <td>0.373016</td>\n",
       "      <td>Personal:0.105 \\n</td>\n",
       "      <td>Personal:0.173 \\n</td>\n",
       "      <td>Personal:0.097 \\n</td>\n",
       "      <td>0.415405</td>\n",
       "      <td>Personal:0.343 \\n</td>\n",
       "      <td>Personal:0.142 \\n</td>\n",
       "      <td>Personal:0.083 \\n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Dataset ReduceDsize Eq_Estrat            Envs Seed Fteng Bin  \\\n",
       "Id                                                                \n",
       "0    adult          -1        -1       workclass   52    -1   0   \n",
       "1    adult          -1        -1  native-country   52    -1   0   \n",
       "2    adult          -1        -1    relationship   52    -1   0   \n",
       "3   german          -1        -1         Purpose   52    -1   0   \n",
       "4   german          -1        -1         Housing   52    -1   0   \n",
       "\n",
       "                 TestSet  irm-train_error-ACC  \\\n",
       "Id                                              \n",
       "0        workclass_DUMmY             0.727994   \n",
       "1   native-country_DUMmY             0.708622   \n",
       "2     relationship_DUMmY             0.861698   \n",
       "3          Purpose_DUMmY             0.432023   \n",
       "4          Housing_DUMmY             0.373016   \n",
       "\n",
       "                                   irm-train_fairness-DP  \\\n",
       "Id                                                         \n",
       "0    race:0.034 \\n gender:0.016 \\n relationship:0.105 \\n   \n",
       "1    race:0.092 \\n gender:0.037 \\n relationship:0.205 \\n   \n",
       "2    race:0.037 \\n gender:0.010 \\n relationship:0.187 \\n   \n",
       "3                                      Personal:0.124 \\n   \n",
       "4                                      Personal:0.105 \\n   \n",
       "\n",
       "                                  irm-train_fairness-EOP  \\\n",
       "Id                                                         \n",
       "0    race:0.080 \\n gender:0.012 \\n relationship:0.207 \\n   \n",
       "1    race:0.116 \\n gender:0.015 \\n relationship:0.128 \\n   \n",
       "2    race:0.169 \\n gender:0.024 \\n relationship:0.131 \\n   \n",
       "3                                      Personal:0.164 \\n   \n",
       "4                                      Personal:0.173 \\n   \n",
       "\n",
       "                                  irm-train_fairness-CAL  irm-test_error-ACC  \\\n",
       "Id                                                                             \n",
       "0    race:0.031 \\n gender:0.018 \\n relationship:0.102 \\n            0.591752   \n",
       "1    race:0.070 \\n gender:0.031 \\n relationship:0.171 \\n            0.642012   \n",
       "2    race:0.023 \\n gender:0.007 \\n relationship:0.162 \\n            0.535234   \n",
       "3                                      Personal:0.055 \\n            0.481591   \n",
       "4                                      Personal:0.097 \\n            0.415405   \n",
       "\n",
       "                                    irm-test_fairness-DP  \\\n",
       "Id                                                         \n",
       "0    race:0.163 \\n gender:0.021 \\n relationship:0.111 \\n   \n",
       "1      race:nan \\n gender:0.023 \\n relationship:0.111 \\n   \n",
       "2        race:0.085 \\n gender:nan \\n relationship:nan \\n   \n",
       "3                                      Personal:0.345 \\n   \n",
       "4                                      Personal:0.343 \\n   \n",
       "\n",
       "                                   irm-test_fairness-EOP  \\\n",
       "Id                                                         \n",
       "0    race:0.263 \\n gender:0.021 \\n relationship:0.385 \\n   \n",
       "1      race:nan \\n gender:0.062 \\n relationship:0.333 \\n   \n",
       "2        race:0.096 \\n gender:nan \\n relationship:nan \\n   \n",
       "3                                      Personal:0.345 \\n   \n",
       "4                                      Personal:0.142 \\n   \n",
       "\n",
       "                                   irm-test_fairness-CAL  \n",
       "Id                                                        \n",
       "0    race:0.145 \\n gender:0.021 \\n relationship:0.129 \\n  \n",
       "1      race:nan \\n gender:0.023 \\n relationship:0.111 \\n  \n",
       "2        race:0.084 \\n gender:nan \\n relationship:nan \\n  \n",
       "3                                      Personal:0.234 \\n  \n",
       "4                                      Personal:0.083 \\n  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.options.display.max_colwidth = 4000\n",
    "invar_results.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating on Non-Invariance Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-10T18:44:50.506834Z",
     "start_time": "2020-06-10T18:44:50.485836Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>ReduceDsize</th>\n",
       "      <th>Bin</th>\n",
       "      <th>Fteng</th>\n",
       "      <th>Seed</th>\n",
       "      <th>TestSet</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>adult</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>52</td>\n",
       "      <td>workclass_DUMmY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>adult</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>52</td>\n",
       "      <td>native-country_DUMmY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>adult</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>52</td>\n",
       "      <td>relationship_DUMmY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>german</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>52</td>\n",
       "      <td>Purpose_DUMmY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>german</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>52</td>\n",
       "      <td>Housing_DUMmY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Dataset ReduceDsize Bin Fteng Seed               TestSet\n",
       "Id                                                         \n",
       "0    adult          -1   0    -1   52       workclass_DUMmY\n",
       "1    adult          -1   0    -1   52  native-country_DUMmY\n",
       "2    adult          -1   0    -1   52    relationship_DUMmY\n",
       "3   german          -1   0    -1   52         Purpose_DUMmY\n",
       "4   german          -1   0    -1   52         Housing_DUMmY"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var_FIXED = [['Dataset', 'adult'], \\\n",
    "               ['ReduceDsize', 10000], \\\n",
    "               ['Bin', 1]] \n",
    "\n",
    "var_COMPARED =  {'Fteng':['1', '12'], \\\n",
    "                 'Seed':[147, 256, 304]}\n",
    "\n",
    "var_orig_cols = [a[0] for a in var_FIXED] + list(var_COMPARED.keys()) + ['TestSet']\n",
    "var_results = generate_all_existing_results(var_orig_cols, \\\n",
    "                                             [non_invariance_algos[a]['params'] for a in list(non_invariance_algos.keys())]) \n",
    "# var_results = generate_results(var_FIXED, var_COMPARED)\n",
    "\n",
    "var_results.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-10T18:45:35.958921Z",
     "start_time": "2020-06-10T18:45:02.748325Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45086, 91)\n",
      "(43696, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/RobertAdragna/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:18: UserWarning: Using a target size (torch.Size([43696, 1])) that is different to the input size (torch.Size([43696])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(43696, 1)\n",
      "(43696, 1)\n",
      "(43696, 1)\n",
      "(1390, 1)\n",
      "(1390, 1)\n",
      "(1390, 1)\n",
      "(1390, 1)\n",
      "(43696, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/RobertAdragna/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:18: UserWarning: Using a target size (torch.Size([1390, 1])) that is different to the input size (torch.Size([1390])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(43696, 1)\n",
      "(43696, 1)\n",
      "(43696, 1)\n",
      "(1390, 1)\n",
      "(1390, 1)\n",
      "(1390, 1)\n",
      "(1390, 1)\n",
      "(43696, 1)\n",
      "(43696, 1)\n",
      "(43696, 1)\n",
      "(43696, 1)\n",
      "(1390, 1)\n",
      "(1390, 1)\n",
      "(1390, 1)\n",
      "(1390, 1)\n",
      "(45086, 91)\n",
      "(45060, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/RobertAdragna/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:18: UserWarning: Using a target size (torch.Size([45060, 1])) that is different to the input size (torch.Size([45060])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45060, 1)\n",
      "(45060, 1)\n",
      "(45060, 1)\n",
      "(26, 1)\n",
      "(26, 1)\n",
      "(26, 1)\n",
      "(26, 1)\n",
      "(45060, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/RobertAdragna/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:18: UserWarning: Using a target size (torch.Size([26, 1])) that is different to the input size (torch.Size([26])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45060, 1)\n",
      "(45060, 1)\n",
      "(45060, 1)\n",
      "(26, 1)\n",
      "(26, 1)\n",
      "(26, 1)\n",
      "(26, 1)\n",
      "(45060, 1)\n",
      "(45060, 1)\n",
      "(45060, 1)\n",
      "(45060, 1)\n",
      "(26, 1)\n",
      "(26, 1)\n",
      "(26, 1)\n",
      "(26, 1)\n",
      "(45086, 91)\n",
      "(26472, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/RobertAdragna/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:18: UserWarning: Using a target size (torch.Size([26472, 1])) that is different to the input size (torch.Size([26472])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26472, 1)\n",
      "(26472, 1)\n",
      "(26472, 1)\n",
      "(18614, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/RobertAdragna/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:18: UserWarning: Using a target size (torch.Size([18614, 1])) that is different to the input size (torch.Size([18614])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18614, 1)\n",
      "(18614, 1)\n",
      "(18614, 1)\n",
      "(26472, 1)\n",
      "(26472, 1)\n",
      "(26472, 1)\n",
      "(26472, 1)\n",
      "(18614, 1)\n",
      "(18614, 1)\n",
      "(18614, 1)\n",
      "(18614, 1)\n",
      "(26472, 1)\n",
      "(26472, 1)\n",
      "(26472, 1)\n",
      "(26472, 1)\n",
      "(18614, 1)\n",
      "(18614, 1)\n",
      "(18614, 1)\n",
      "(18614, 1)\n",
      "(988, 34)\n",
      "(754, 1)\n",
      "(754, 1)\n",
      "(234, 1)\n",
      "(234, 1)\n",
      "(754, 1)\n",
      "(754, 1)\n",
      "(234, 1)\n",
      "(234, 1)\n",
      "(754, 1)\n",
      "(754, 1)\n",
      "(234, 1)\n",
      "(234, 1)\n",
      "(988, 34)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/RobertAdragna/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:18: UserWarning: Using a target size (torch.Size([754, 1])) that is different to the input size (torch.Size([754])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "/Users/RobertAdragna/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:18: UserWarning: Using a target size (torch.Size([234, 1])) that is different to the input size (torch.Size([234])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "/Users/RobertAdragna/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:18: UserWarning: Using a target size (torch.Size([809, 1])) that is different to the input size (torch.Size([809])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "/Users/RobertAdragna/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:18: UserWarning: Using a target size (torch.Size([179, 1])) that is different to the input size (torch.Size([179])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(809, 1)\n",
      "(809, 1)\n",
      "(179, 1)\n",
      "(179, 1)\n",
      "(809, 1)\n",
      "(809, 1)\n",
      "(179, 1)\n",
      "(179, 1)\n",
      "(809, 1)\n",
      "(809, 1)\n",
      "(179, 1)\n",
      "(179, 1)\n"
     ]
    }
   ],
   "source": [
    "compute_results(non_invariance_algos, var_results, var_orig_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-10T18:45:36.105709Z",
     "start_time": "2020-06-10T18:45:36.086372Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>ReduceDsize</th>\n",
       "      <th>Bin</th>\n",
       "      <th>Fteng</th>\n",
       "      <th>Seed</th>\n",
       "      <th>TestSet</th>\n",
       "      <th>linreg-train_error-ACC</th>\n",
       "      <th>linreg-train_fairness-DP</th>\n",
       "      <th>linreg-train_fairness-EOP</th>\n",
       "      <th>linreg-train_fairness-CAL</th>\n",
       "      <th>linreg-test_error-ACC</th>\n",
       "      <th>linreg-test_fairness-DP</th>\n",
       "      <th>linreg-test_fairness-EOP</th>\n",
       "      <th>linreg-test_fairness-CAL</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>adult</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>52</td>\n",
       "      <td>workclass_DUMmY</td>\n",
       "      <td>0.671958</td>\n",
       "      <td>race:0.203 \\n gender:0.077 \\n relationship:0.494 \\n</td>\n",
       "      <td>race:0.404 \\n gender:0.059 \\n relationship:0.669 \\n</td>\n",
       "      <td>race:0.152 \\n gender:0.058 \\n relationship:0.368 \\n</td>\n",
       "      <td>0.562679</td>\n",
       "      <td>race:0.378 \\n gender:0.106 \\n relationship:0.469 \\n</td>\n",
       "      <td>race:0.688 \\n gender:0.091 \\n relationship:0.569 \\n</td>\n",
       "      <td>race:0.342 \\n gender:0.089 \\n relationship:0.386 \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>adult</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>52</td>\n",
       "      <td>native-country_DUMmY</td>\n",
       "      <td>0.665347</td>\n",
       "      <td>race:0.217 \\n gender:0.080 \\n relationship:0.517 \\n</td>\n",
       "      <td>race:0.406 \\n gender:0.059 \\n relationship:0.687 \\n</td>\n",
       "      <td>race:0.164 \\n gender:0.060 \\n relationship:0.383 \\n</td>\n",
       "      <td>0.642012</td>\n",
       "      <td>race:nan \\n gender:0.125 \\n relationship:0.111 \\n</td>\n",
       "      <td>race:nan \\n gender:0.500 \\n relationship:0.333 \\n</td>\n",
       "      <td>race:nan \\n gender:0.125 \\n relationship:0.111 \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>adult</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>52</td>\n",
       "      <td>relationship_DUMmY</td>\n",
       "      <td>0.870632</td>\n",
       "      <td>race:0.040 \\n gender:0.021 \\n relationship:0.279 \\n</td>\n",
       "      <td>race:0.145 \\n gender:0.126 \\n relationship:0.406 \\n</td>\n",
       "      <td>race:0.028 \\n gender:0.016 \\n relationship:0.217 \\n</td>\n",
       "      <td>0.537267</td>\n",
       "      <td>race:0.150 \\n gender:nan \\n relationship:nan \\n</td>\n",
       "      <td>race:0.227 \\n gender:nan \\n relationship:nan \\n</td>\n",
       "      <td>race:0.125 \\n gender:nan \\n relationship:nan \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>german</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>52</td>\n",
       "      <td>Purpose_DUMmY</td>\n",
       "      <td>0.645579</td>\n",
       "      <td>Personal:0.234 \\n</td>\n",
       "      <td>Personal:0.126 \\n</td>\n",
       "      <td>Personal:0.211 \\n</td>\n",
       "      <td>0.584886</td>\n",
       "      <td>Personal:0.130 \\n</td>\n",
       "      <td>Personal:0.110 \\n</td>\n",
       "      <td>Personal:0.141 \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>german</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>52</td>\n",
       "      <td>Housing_DUMmY</td>\n",
       "      <td>0.640148</td>\n",
       "      <td>Personal:0.138 \\n</td>\n",
       "      <td>Personal:0.044 \\n</td>\n",
       "      <td>Personal:0.088 \\n</td>\n",
       "      <td>0.574857</td>\n",
       "      <td>Personal:0.150 \\n</td>\n",
       "      <td>Personal:0.034 \\n</td>\n",
       "      <td>Personal:0.442 \\n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Dataset ReduceDsize Bin Fteng Seed               TestSet  \\\n",
       "Id                                                            \n",
       "0    adult          -1   0    -1   52       workclass_DUMmY   \n",
       "1    adult          -1   0    -1   52  native-country_DUMmY   \n",
       "2    adult          -1   0    -1   52    relationship_DUMmY   \n",
       "3   german          -1   0    -1   52         Purpose_DUMmY   \n",
       "4   german          -1   0    -1   52         Housing_DUMmY   \n",
       "\n",
       "    linreg-train_error-ACC  \\\n",
       "Id                           \n",
       "0                 0.671958   \n",
       "1                 0.665347   \n",
       "2                 0.870632   \n",
       "3                 0.645579   \n",
       "4                 0.640148   \n",
       "\n",
       "                                linreg-train_fairness-DP  \\\n",
       "Id                                                         \n",
       "0    race:0.203 \\n gender:0.077 \\n relationship:0.494 \\n   \n",
       "1    race:0.217 \\n gender:0.080 \\n relationship:0.517 \\n   \n",
       "2    race:0.040 \\n gender:0.021 \\n relationship:0.279 \\n   \n",
       "3                                      Personal:0.234 \\n   \n",
       "4                                      Personal:0.138 \\n   \n",
       "\n",
       "                               linreg-train_fairness-EOP  \\\n",
       "Id                                                         \n",
       "0    race:0.404 \\n gender:0.059 \\n relationship:0.669 \\n   \n",
       "1    race:0.406 \\n gender:0.059 \\n relationship:0.687 \\n   \n",
       "2    race:0.145 \\n gender:0.126 \\n relationship:0.406 \\n   \n",
       "3                                      Personal:0.126 \\n   \n",
       "4                                      Personal:0.044 \\n   \n",
       "\n",
       "                               linreg-train_fairness-CAL  \\\n",
       "Id                                                         \n",
       "0    race:0.152 \\n gender:0.058 \\n relationship:0.368 \\n   \n",
       "1    race:0.164 \\n gender:0.060 \\n relationship:0.383 \\n   \n",
       "2    race:0.028 \\n gender:0.016 \\n relationship:0.217 \\n   \n",
       "3                                      Personal:0.211 \\n   \n",
       "4                                      Personal:0.088 \\n   \n",
       "\n",
       "    linreg-test_error-ACC  \\\n",
       "Id                          \n",
       "0                0.562679   \n",
       "1                0.642012   \n",
       "2                0.537267   \n",
       "3                0.584886   \n",
       "4                0.574857   \n",
       "\n",
       "                                 linreg-test_fairness-DP  \\\n",
       "Id                                                         \n",
       "0    race:0.378 \\n gender:0.106 \\n relationship:0.469 \\n   \n",
       "1      race:nan \\n gender:0.125 \\n relationship:0.111 \\n   \n",
       "2        race:0.150 \\n gender:nan \\n relationship:nan \\n   \n",
       "3                                      Personal:0.130 \\n   \n",
       "4                                      Personal:0.150 \\n   \n",
       "\n",
       "                                linreg-test_fairness-EOP  \\\n",
       "Id                                                         \n",
       "0    race:0.688 \\n gender:0.091 \\n relationship:0.569 \\n   \n",
       "1      race:nan \\n gender:0.500 \\n relationship:0.333 \\n   \n",
       "2        race:0.227 \\n gender:nan \\n relationship:nan \\n   \n",
       "3                                      Personal:0.110 \\n   \n",
       "4                                      Personal:0.034 \\n   \n",
       "\n",
       "                                linreg-test_fairness-CAL  \n",
       "Id                                                        \n",
       "0    race:0.342 \\n gender:0.089 \\n relationship:0.386 \\n  \n",
       "1      race:nan \\n gender:0.125 \\n relationship:0.111 \\n  \n",
       "2        race:0.125 \\n gender:nan \\n relationship:nan \\n  \n",
       "3                                      Personal:0.141 \\n  \n",
       "4                                      Personal:0.442 \\n  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.options.display.max_colwidth = 400\n",
    "var_results.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save To Latex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-10T18:46:58.219275Z",
     "start_time": "2020-06-10T18:46:58.005507Z"
    }
   },
   "outputs": [],
   "source": [
    "latex_resdir = 'latex_results'\n",
    "latex_fname = '0609_linreg_test.xlsx'\n",
    "var_results.to_excel(os.path.join(latex_resdir, latex_fname))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
